{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { SENSITIVE_STRING } from \"@aws-sdk/smithy-client\";\nexport var BufferingHints;\n(function (BufferingHints) {\n  BufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(BufferingHints || (BufferingHints = {}));\nexport var CloudWatchLoggingOptions;\n(function (CloudWatchLoggingOptions) {\n  CloudWatchLoggingOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(CloudWatchLoggingOptions || (CloudWatchLoggingOptions = {}));\nexport var CompressionFormat;\n(function (CompressionFormat) {\n  CompressionFormat[\"GZIP\"] = \"GZIP\";\n  CompressionFormat[\"HADOOP_SNAPPY\"] = \"HADOOP_SNAPPY\";\n  CompressionFormat[\"SNAPPY\"] = \"Snappy\";\n  CompressionFormat[\"UNCOMPRESSED\"] = \"UNCOMPRESSED\";\n  CompressionFormat[\"ZIP\"] = \"ZIP\";\n})(CompressionFormat || (CompressionFormat = {}));\nexport var ConcurrentModificationException;\n(function (ConcurrentModificationException) {\n  ConcurrentModificationException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ConcurrentModificationException || (ConcurrentModificationException = {}));\nexport var ContentEncoding;\n(function (ContentEncoding) {\n  ContentEncoding[\"GZIP\"] = \"GZIP\";\n  ContentEncoding[\"NONE\"] = \"NONE\";\n})(ContentEncoding || (ContentEncoding = {}));\nexport var CopyCommand;\n(function (CopyCommand) {\n  CopyCommand.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(CopyCommand || (CopyCommand = {}));\nexport var KeyType;\n(function (KeyType) {\n  KeyType[\"AWS_OWNED_CMK\"] = \"AWS_OWNED_CMK\";\n  KeyType[\"CUSTOMER_MANAGED_CMK\"] = \"CUSTOMER_MANAGED_CMK\";\n})(KeyType || (KeyType = {}));\nexport var DeliveryStreamEncryptionConfigurationInput;\n(function (DeliveryStreamEncryptionConfigurationInput) {\n  DeliveryStreamEncryptionConfigurationInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DeliveryStreamEncryptionConfigurationInput || (DeliveryStreamEncryptionConfigurationInput = {}));\nexport var ElasticsearchBufferingHints;\n(function (ElasticsearchBufferingHints) {\n  ElasticsearchBufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ElasticsearchBufferingHints || (ElasticsearchBufferingHints = {}));\nexport var ProcessorParameterName;\n(function (ProcessorParameterName) {\n  ProcessorParameterName[\"BUFFER_INTERVAL_IN_SECONDS\"] = \"BufferIntervalInSeconds\";\n  ProcessorParameterName[\"BUFFER_SIZE_IN_MB\"] = \"BufferSizeInMBs\";\n  ProcessorParameterName[\"LAMBDA_ARN\"] = \"LambdaArn\";\n  ProcessorParameterName[\"LAMBDA_NUMBER_OF_RETRIES\"] = \"NumberOfRetries\";\n  ProcessorParameterName[\"ROLE_ARN\"] = \"RoleArn\";\n})(ProcessorParameterName || (ProcessorParameterName = {}));\nexport var ProcessorParameter;\n(function (ProcessorParameter) {\n  ProcessorParameter.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ProcessorParameter || (ProcessorParameter = {}));\nexport var Processor;\n(function (Processor) {\n  Processor.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(Processor || (Processor = {}));\nexport var ProcessingConfiguration;\n(function (ProcessingConfiguration) {\n  ProcessingConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ProcessingConfiguration || (ProcessingConfiguration = {}));\nexport var ElasticsearchRetryOptions;\n(function (ElasticsearchRetryOptions) {\n  ElasticsearchRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ElasticsearchRetryOptions || (ElasticsearchRetryOptions = {}));\nexport var KMSEncryptionConfig;\n(function (KMSEncryptionConfig) {\n  KMSEncryptionConfig.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(KMSEncryptionConfig || (KMSEncryptionConfig = {}));\nexport var EncryptionConfiguration;\n(function (EncryptionConfiguration) {\n  EncryptionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(EncryptionConfiguration || (EncryptionConfiguration = {}));\nexport var S3DestinationConfiguration;\n(function (S3DestinationConfiguration) {\n  S3DestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(S3DestinationConfiguration || (S3DestinationConfiguration = {}));\nexport var VpcConfiguration;\n(function (VpcConfiguration) {\n  VpcConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(VpcConfiguration || (VpcConfiguration = {}));\nexport var ElasticsearchDestinationConfiguration;\n(function (ElasticsearchDestinationConfiguration) {\n  ElasticsearchDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ElasticsearchDestinationConfiguration || (ElasticsearchDestinationConfiguration = {}));\nexport var HiveJsonSerDe;\n(function (HiveJsonSerDe) {\n  HiveJsonSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(HiveJsonSerDe || (HiveJsonSerDe = {}));\nexport var OpenXJsonSerDe;\n(function (OpenXJsonSerDe) {\n  OpenXJsonSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(OpenXJsonSerDe || (OpenXJsonSerDe = {}));\nexport var Deserializer;\n(function (Deserializer) {\n  Deserializer.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(Deserializer || (Deserializer = {}));\nexport var InputFormatConfiguration;\n(function (InputFormatConfiguration) {\n  InputFormatConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(InputFormatConfiguration || (InputFormatConfiguration = {}));\nexport var OrcCompression;\n(function (OrcCompression) {\n  OrcCompression[\"NONE\"] = \"NONE\";\n  OrcCompression[\"SNAPPY\"] = \"SNAPPY\";\n  OrcCompression[\"ZLIB\"] = \"ZLIB\";\n})(OrcCompression || (OrcCompression = {}));\nexport var OrcFormatVersion;\n(function (OrcFormatVersion) {\n  OrcFormatVersion[\"V0_11\"] = \"V0_11\";\n  OrcFormatVersion[\"V0_12\"] = \"V0_12\";\n})(OrcFormatVersion || (OrcFormatVersion = {}));\nexport var OrcSerDe;\n(function (OrcSerDe) {\n  OrcSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(OrcSerDe || (OrcSerDe = {}));\nexport var ParquetCompression;\n(function (ParquetCompression) {\n  ParquetCompression[\"GZIP\"] = \"GZIP\";\n  ParquetCompression[\"SNAPPY\"] = \"SNAPPY\";\n  ParquetCompression[\"UNCOMPRESSED\"] = \"UNCOMPRESSED\";\n})(ParquetCompression || (ParquetCompression = {}));\nexport var ParquetWriterVersion;\n(function (ParquetWriterVersion) {\n  ParquetWriterVersion[\"V1\"] = \"V1\";\n  ParquetWriterVersion[\"V2\"] = \"V2\";\n})(ParquetWriterVersion || (ParquetWriterVersion = {}));\nexport var ParquetSerDe;\n(function (ParquetSerDe) {\n  ParquetSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ParquetSerDe || (ParquetSerDe = {}));\nexport var Serializer;\n(function (Serializer) {\n  Serializer.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(Serializer || (Serializer = {}));\nexport var OutputFormatConfiguration;\n(function (OutputFormatConfiguration) {\n  OutputFormatConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(OutputFormatConfiguration || (OutputFormatConfiguration = {}));\nexport var SchemaConfiguration;\n(function (SchemaConfiguration) {\n  SchemaConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SchemaConfiguration || (SchemaConfiguration = {}));\nexport var DataFormatConversionConfiguration;\n(function (DataFormatConversionConfiguration) {\n  DataFormatConversionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DataFormatConversionConfiguration || (DataFormatConversionConfiguration = {}));\nexport var ExtendedS3DestinationConfiguration;\n(function (ExtendedS3DestinationConfiguration) {\n  ExtendedS3DestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ExtendedS3DestinationConfiguration || (ExtendedS3DestinationConfiguration = {}));\nexport var HttpEndpointBufferingHints;\n(function (HttpEndpointBufferingHints) {\n  HttpEndpointBufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(HttpEndpointBufferingHints || (HttpEndpointBufferingHints = {}));\nexport var HttpEndpointConfiguration;\n(function (HttpEndpointConfiguration) {\n  HttpEndpointConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.Url && {\n      Url: SENSITIVE_STRING\n    }), obj.AccessKey && {\n      AccessKey: SENSITIVE_STRING\n    });\n  };\n})(HttpEndpointConfiguration || (HttpEndpointConfiguration = {}));\nexport var HttpEndpointCommonAttribute;\n(function (HttpEndpointCommonAttribute) {\n  HttpEndpointCommonAttribute.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.AttributeName && {\n      AttributeName: SENSITIVE_STRING\n    }), obj.AttributeValue && {\n      AttributeValue: SENSITIVE_STRING\n    });\n  };\n})(HttpEndpointCommonAttribute || (HttpEndpointCommonAttribute = {}));\nexport var HttpEndpointRequestConfiguration;\n(function (HttpEndpointRequestConfiguration) {\n  HttpEndpointRequestConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.CommonAttributes && {\n      CommonAttributes: obj.CommonAttributes.map(function (item) {\n        return HttpEndpointCommonAttribute.filterSensitiveLog(item);\n      })\n    });\n  };\n})(HttpEndpointRequestConfiguration || (HttpEndpointRequestConfiguration = {}));\nexport var HttpEndpointRetryOptions;\n(function (HttpEndpointRetryOptions) {\n  HttpEndpointRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(HttpEndpointRetryOptions || (HttpEndpointRetryOptions = {}));\nexport var HttpEndpointDestinationConfiguration;\n(function (HttpEndpointDestinationConfiguration) {\n  HttpEndpointDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration)\n    }), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    });\n  };\n})(HttpEndpointDestinationConfiguration || (HttpEndpointDestinationConfiguration = {}));\nexport var KinesisStreamSourceConfiguration;\n(function (KinesisStreamSourceConfiguration) {\n  KinesisStreamSourceConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(KinesisStreamSourceConfiguration || (KinesisStreamSourceConfiguration = {}));\nexport var RedshiftRetryOptions;\n(function (RedshiftRetryOptions) {\n  RedshiftRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(RedshiftRetryOptions || (RedshiftRetryOptions = {}));\nexport var RedshiftDestinationConfiguration;\n(function (RedshiftDestinationConfiguration) {\n  RedshiftDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    }), obj.Password && {\n      Password: SENSITIVE_STRING\n    });\n  };\n})(RedshiftDestinationConfiguration || (RedshiftDestinationConfiguration = {}));\nexport var SplunkRetryOptions;\n(function (SplunkRetryOptions) {\n  SplunkRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SplunkRetryOptions || (SplunkRetryOptions = {}));\nexport var SplunkDestinationConfiguration;\n(function (SplunkDestinationConfiguration) {\n  SplunkDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SplunkDestinationConfiguration || (SplunkDestinationConfiguration = {}));\nexport var Tag;\n(function (Tag) {\n  Tag.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(Tag || (Tag = {}));\nexport var CreateDeliveryStreamInput;\n(function (CreateDeliveryStreamInput) {\n  CreateDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RedshiftDestinationConfiguration && {\n      RedshiftDestinationConfiguration: RedshiftDestinationConfiguration.filterSensitiveLog(obj.RedshiftDestinationConfiguration)\n    }), obj.HttpEndpointDestinationConfiguration && {\n      HttpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration.filterSensitiveLog(obj.HttpEndpointDestinationConfiguration)\n    });\n  };\n})(CreateDeliveryStreamInput || (CreateDeliveryStreamInput = {}));\nexport var CreateDeliveryStreamOutput;\n(function (CreateDeliveryStreamOutput) {\n  CreateDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(CreateDeliveryStreamOutput || (CreateDeliveryStreamOutput = {}));\nexport var InvalidArgumentException;\n(function (InvalidArgumentException) {\n  InvalidArgumentException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(InvalidArgumentException || (InvalidArgumentException = {}));\nexport var InvalidKMSResourceException;\n(function (InvalidKMSResourceException) {\n  InvalidKMSResourceException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(InvalidKMSResourceException || (InvalidKMSResourceException = {}));\nexport var LimitExceededException;\n(function (LimitExceededException) {\n  LimitExceededException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(LimitExceededException || (LimitExceededException = {}));\nexport var ResourceInUseException;\n(function (ResourceInUseException) {\n  ResourceInUseException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ResourceInUseException || (ResourceInUseException = {}));\nexport var DeleteDeliveryStreamInput;\n(function (DeleteDeliveryStreamInput) {\n  DeleteDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DeleteDeliveryStreamInput || (DeleteDeliveryStreamInput = {}));\nexport var DeleteDeliveryStreamOutput;\n(function (DeleteDeliveryStreamOutput) {\n  DeleteDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DeleteDeliveryStreamOutput || (DeleteDeliveryStreamOutput = {}));\nexport var ResourceNotFoundException;\n(function (ResourceNotFoundException) {\n  ResourceNotFoundException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ResourceNotFoundException || (ResourceNotFoundException = {}));\nexport var DeliveryStreamFailureType;\n(function (DeliveryStreamFailureType) {\n  DeliveryStreamFailureType[\"CREATE_ENI_FAILED\"] = \"CREATE_ENI_FAILED\";\n  DeliveryStreamFailureType[\"CREATE_KMS_GRANT_FAILED\"] = \"CREATE_KMS_GRANT_FAILED\";\n  DeliveryStreamFailureType[\"DELETE_ENI_FAILED\"] = \"DELETE_ENI_FAILED\";\n  DeliveryStreamFailureType[\"DISABLED_KMS_KEY\"] = \"DISABLED_KMS_KEY\";\n  DeliveryStreamFailureType[\"ENI_ACCESS_DENIED\"] = \"ENI_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"INVALID_KMS_KEY\"] = \"INVALID_KMS_KEY\";\n  DeliveryStreamFailureType[\"KMS_ACCESS_DENIED\"] = \"KMS_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"KMS_KEY_NOT_FOUND\"] = \"KMS_KEY_NOT_FOUND\";\n  DeliveryStreamFailureType[\"KMS_OPT_IN_REQUIRED\"] = \"KMS_OPT_IN_REQUIRED\";\n  DeliveryStreamFailureType[\"RETIRE_KMS_GRANT_FAILED\"] = \"RETIRE_KMS_GRANT_FAILED\";\n  DeliveryStreamFailureType[\"SECURITY_GROUP_ACCESS_DENIED\"] = \"SECURITY_GROUP_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"SECURITY_GROUP_NOT_FOUND\"] = \"SECURITY_GROUP_NOT_FOUND\";\n  DeliveryStreamFailureType[\"SUBNET_ACCESS_DENIED\"] = \"SUBNET_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"SUBNET_NOT_FOUND\"] = \"SUBNET_NOT_FOUND\";\n  DeliveryStreamFailureType[\"UNKNOWN_ERROR\"] = \"UNKNOWN_ERROR\";\n})(DeliveryStreamFailureType || (DeliveryStreamFailureType = {}));\nexport var FailureDescription;\n(function (FailureDescription) {\n  FailureDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(FailureDescription || (FailureDescription = {}));\nexport var DeliveryStreamEncryptionStatus;\n(function (DeliveryStreamEncryptionStatus) {\n  DeliveryStreamEncryptionStatus[\"DISABLED\"] = \"DISABLED\";\n  DeliveryStreamEncryptionStatus[\"DISABLING\"] = \"DISABLING\";\n  DeliveryStreamEncryptionStatus[\"DISABLING_FAILED\"] = \"DISABLING_FAILED\";\n  DeliveryStreamEncryptionStatus[\"ENABLED\"] = \"ENABLED\";\n  DeliveryStreamEncryptionStatus[\"ENABLING\"] = \"ENABLING\";\n  DeliveryStreamEncryptionStatus[\"ENABLING_FAILED\"] = \"ENABLING_FAILED\";\n})(DeliveryStreamEncryptionStatus || (DeliveryStreamEncryptionStatus = {}));\nexport var DeliveryStreamEncryptionConfiguration;\n(function (DeliveryStreamEncryptionConfiguration) {\n  DeliveryStreamEncryptionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DeliveryStreamEncryptionConfiguration || (DeliveryStreamEncryptionConfiguration = {}));\nexport var DeliveryStreamStatus;\n(function (DeliveryStreamStatus) {\n  DeliveryStreamStatus[\"ACTIVE\"] = \"ACTIVE\";\n  DeliveryStreamStatus[\"CREATING\"] = \"CREATING\";\n  DeliveryStreamStatus[\"CREATING_FAILED\"] = \"CREATING_FAILED\";\n  DeliveryStreamStatus[\"DELETING\"] = \"DELETING\";\n  DeliveryStreamStatus[\"DELETING_FAILED\"] = \"DELETING_FAILED\";\n})(DeliveryStreamStatus || (DeliveryStreamStatus = {}));\nexport var S3DestinationDescription;\n(function (S3DestinationDescription) {\n  S3DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(S3DestinationDescription || (S3DestinationDescription = {}));\nexport var VpcConfigurationDescription;\n(function (VpcConfigurationDescription) {\n  VpcConfigurationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(VpcConfigurationDescription || (VpcConfigurationDescription = {}));\nexport var ElasticsearchDestinationDescription;\n(function (ElasticsearchDestinationDescription) {\n  ElasticsearchDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ElasticsearchDestinationDescription || (ElasticsearchDestinationDescription = {}));\nexport var ExtendedS3DestinationDescription;\n(function (ExtendedS3DestinationDescription) {\n  ExtendedS3DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ExtendedS3DestinationDescription || (ExtendedS3DestinationDescription = {}));\nexport var HttpEndpointDescription;\n(function (HttpEndpointDescription) {\n  HttpEndpointDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Url && {\n      Url: SENSITIVE_STRING\n    });\n  };\n})(HttpEndpointDescription || (HttpEndpointDescription = {}));\nexport var HttpEndpointDestinationDescription;\n(function (HttpEndpointDestinationDescription) {\n  HttpEndpointDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointDescription.filterSensitiveLog(obj.EndpointConfiguration)\n    }), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    });\n  };\n})(HttpEndpointDestinationDescription || (HttpEndpointDestinationDescription = {}));\nexport var RedshiftDestinationDescription;\n(function (RedshiftDestinationDescription) {\n  RedshiftDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    });\n  };\n})(RedshiftDestinationDescription || (RedshiftDestinationDescription = {}));\nexport var SplunkDestinationDescription;\n(function (SplunkDestinationDescription) {\n  SplunkDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SplunkDestinationDescription || (SplunkDestinationDescription = {}));\nexport var DestinationDescription;\n(function (DestinationDescription) {\n  DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RedshiftDestinationDescription && {\n      RedshiftDestinationDescription: RedshiftDestinationDescription.filterSensitiveLog(obj.RedshiftDestinationDescription)\n    }), obj.HttpEndpointDestinationDescription && {\n      HttpEndpointDestinationDescription: HttpEndpointDestinationDescription.filterSensitiveLog(obj.HttpEndpointDestinationDescription)\n    });\n  };\n})(DestinationDescription || (DestinationDescription = {}));\nexport var KinesisStreamSourceDescription;\n(function (KinesisStreamSourceDescription) {\n  KinesisStreamSourceDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(KinesisStreamSourceDescription || (KinesisStreamSourceDescription = {}));\nexport var SourceDescription;\n(function (SourceDescription) {\n  SourceDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SourceDescription || (SourceDescription = {}));\nexport var DeliveryStreamDescription;\n(function (DeliveryStreamDescription) {\n  DeliveryStreamDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Destinations && {\n      Destinations: obj.Destinations.map(function (item) {\n        return DestinationDescription.filterSensitiveLog(item);\n      })\n    });\n  };\n})(DeliveryStreamDescription || (DeliveryStreamDescription = {}));\nexport var DescribeDeliveryStreamInput;\n(function (DescribeDeliveryStreamInput) {\n  DescribeDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(DescribeDeliveryStreamInput || (DescribeDeliveryStreamInput = {}));\nexport var DescribeDeliveryStreamOutput;\n(function (DescribeDeliveryStreamOutput) {\n  DescribeDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.DeliveryStreamDescription && {\n      DeliveryStreamDescription: DeliveryStreamDescription.filterSensitiveLog(obj.DeliveryStreamDescription)\n    });\n  };\n})(DescribeDeliveryStreamOutput || (DescribeDeliveryStreamOutput = {}));\nexport var S3DestinationUpdate;\n(function (S3DestinationUpdate) {\n  S3DestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(S3DestinationUpdate || (S3DestinationUpdate = {}));\nexport var ElasticsearchDestinationUpdate;\n(function (ElasticsearchDestinationUpdate) {\n  ElasticsearchDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ElasticsearchDestinationUpdate || (ElasticsearchDestinationUpdate = {}));\nexport var ExtendedS3DestinationUpdate;\n(function (ExtendedS3DestinationUpdate) {\n  ExtendedS3DestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ExtendedS3DestinationUpdate || (ExtendedS3DestinationUpdate = {}));\nexport var ListDeliveryStreamsInput;\n(function (ListDeliveryStreamsInput) {\n  ListDeliveryStreamsInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ListDeliveryStreamsInput || (ListDeliveryStreamsInput = {}));\nexport var ListDeliveryStreamsOutput;\n(function (ListDeliveryStreamsOutput) {\n  ListDeliveryStreamsOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ListDeliveryStreamsOutput || (ListDeliveryStreamsOutput = {}));\nexport var ListTagsForDeliveryStreamInput;\n(function (ListTagsForDeliveryStreamInput) {\n  ListTagsForDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ListTagsForDeliveryStreamInput || (ListTagsForDeliveryStreamInput = {}));\nexport var ListTagsForDeliveryStreamOutput;\n(function (ListTagsForDeliveryStreamOutput) {\n  ListTagsForDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ListTagsForDeliveryStreamOutput || (ListTagsForDeliveryStreamOutput = {}));\nexport var _Record;\n(function (_Record) {\n  _Record.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(_Record || (_Record = {}));\nexport var PutRecordInput;\n(function (PutRecordInput) {\n  PutRecordInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(PutRecordInput || (PutRecordInput = {}));\nexport var PutRecordOutput;\n(function (PutRecordOutput) {\n  PutRecordOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(PutRecordOutput || (PutRecordOutput = {}));\nexport var ServiceUnavailableException;\n(function (ServiceUnavailableException) {\n  ServiceUnavailableException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(ServiceUnavailableException || (ServiceUnavailableException = {}));\nexport var PutRecordBatchInput;\n(function (PutRecordBatchInput) {\n  PutRecordBatchInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(PutRecordBatchInput || (PutRecordBatchInput = {}));\nexport var PutRecordBatchResponseEntry;\n(function (PutRecordBatchResponseEntry) {\n  PutRecordBatchResponseEntry.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(PutRecordBatchResponseEntry || (PutRecordBatchResponseEntry = {}));\nexport var PutRecordBatchOutput;\n(function (PutRecordBatchOutput) {\n  PutRecordBatchOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(PutRecordBatchOutput || (PutRecordBatchOutput = {}));\nexport var StartDeliveryStreamEncryptionInput;\n(function (StartDeliveryStreamEncryptionInput) {\n  StartDeliveryStreamEncryptionInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(StartDeliveryStreamEncryptionInput || (StartDeliveryStreamEncryptionInput = {}));\nexport var StartDeliveryStreamEncryptionOutput;\n(function (StartDeliveryStreamEncryptionOutput) {\n  StartDeliveryStreamEncryptionOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(StartDeliveryStreamEncryptionOutput || (StartDeliveryStreamEncryptionOutput = {}));\nexport var StopDeliveryStreamEncryptionInput;\n(function (StopDeliveryStreamEncryptionInput) {\n  StopDeliveryStreamEncryptionInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(StopDeliveryStreamEncryptionInput || (StopDeliveryStreamEncryptionInput = {}));\nexport var StopDeliveryStreamEncryptionOutput;\n(function (StopDeliveryStreamEncryptionOutput) {\n  StopDeliveryStreamEncryptionOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(StopDeliveryStreamEncryptionOutput || (StopDeliveryStreamEncryptionOutput = {}));\nexport var TagDeliveryStreamInput;\n(function (TagDeliveryStreamInput) {\n  TagDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(TagDeliveryStreamInput || (TagDeliveryStreamInput = {}));\nexport var TagDeliveryStreamOutput;\n(function (TagDeliveryStreamOutput) {\n  TagDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(TagDeliveryStreamOutput || (TagDeliveryStreamOutput = {}));\nexport var UntagDeliveryStreamInput;\n(function (UntagDeliveryStreamInput) {\n  UntagDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(UntagDeliveryStreamInput || (UntagDeliveryStreamInput = {}));\nexport var UntagDeliveryStreamOutput;\n(function (UntagDeliveryStreamOutput) {\n  UntagDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(UntagDeliveryStreamOutput || (UntagDeliveryStreamOutput = {}));\nexport var HttpEndpointDestinationUpdate;\n(function (HttpEndpointDestinationUpdate) {\n  HttpEndpointDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration)\n    }), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    });\n  };\n})(HttpEndpointDestinationUpdate || (HttpEndpointDestinationUpdate = {}));\nexport var RedshiftDestinationUpdate;\n(function (RedshiftDestinationUpdate) {\n  RedshiftDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    }), obj.Password && {\n      Password: SENSITIVE_STRING\n    });\n  };\n})(RedshiftDestinationUpdate || (RedshiftDestinationUpdate = {}));\nexport var SplunkDestinationUpdate;\n(function (SplunkDestinationUpdate) {\n  SplunkDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(SplunkDestinationUpdate || (SplunkDestinationUpdate = {}));\nexport var UpdateDestinationInput;\n(function (UpdateDestinationInput) {\n  UpdateDestinationInput.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RedshiftDestinationUpdate && {\n      RedshiftDestinationUpdate: RedshiftDestinationUpdate.filterSensitiveLog(obj.RedshiftDestinationUpdate)\n    }), obj.HttpEndpointDestinationUpdate && {\n      HttpEndpointDestinationUpdate: HttpEndpointDestinationUpdate.filterSensitiveLog(obj.HttpEndpointDestinationUpdate)\n    });\n  };\n})(UpdateDestinationInput || (UpdateDestinationInput = {}));\nexport var UpdateDestinationOutput;\n(function (UpdateDestinationOutput) {\n  UpdateDestinationOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n})(UpdateDestinationOutput || (UpdateDestinationOutput = {}));","map":{"version":3,"names":["SENSITIVE_STRING","BufferingHints","filterSensitiveLog","obj","__assign","CloudWatchLoggingOptions","CompressionFormat","ConcurrentModificationException","ContentEncoding","CopyCommand","KeyType","DeliveryStreamEncryptionConfigurationInput","ElasticsearchBufferingHints","ProcessorParameterName","ProcessorParameter","Processor","ProcessingConfiguration","ElasticsearchRetryOptions","KMSEncryptionConfig","EncryptionConfiguration","S3DestinationConfiguration","VpcConfiguration","ElasticsearchDestinationConfiguration","HiveJsonSerDe","OpenXJsonSerDe","Deserializer","InputFormatConfiguration","OrcCompression","OrcFormatVersion","OrcSerDe","ParquetCompression","ParquetWriterVersion","ParquetSerDe","Serializer","OutputFormatConfiguration","SchemaConfiguration","DataFormatConversionConfiguration","ExtendedS3DestinationConfiguration","HttpEndpointBufferingHints","HttpEndpointConfiguration","Url","AccessKey","HttpEndpointCommonAttribute","AttributeName","AttributeValue","HttpEndpointRequestConfiguration","CommonAttributes","map","item","HttpEndpointRetryOptions","HttpEndpointDestinationConfiguration","EndpointConfiguration","RequestConfiguration","KinesisStreamSourceConfiguration","RedshiftRetryOptions","RedshiftDestinationConfiguration","Username","Password","SplunkRetryOptions","SplunkDestinationConfiguration","Tag","CreateDeliveryStreamInput","CreateDeliveryStreamOutput","InvalidArgumentException","InvalidKMSResourceException","LimitExceededException","ResourceInUseException","DeleteDeliveryStreamInput","DeleteDeliveryStreamOutput","ResourceNotFoundException","DeliveryStreamFailureType","FailureDescription","DeliveryStreamEncryptionStatus","DeliveryStreamEncryptionConfiguration","DeliveryStreamStatus","S3DestinationDescription","VpcConfigurationDescription","ElasticsearchDestinationDescription","ExtendedS3DestinationDescription","HttpEndpointDescription","HttpEndpointDestinationDescription","RedshiftDestinationDescription","SplunkDestinationDescription","DestinationDescription","KinesisStreamSourceDescription","SourceDescription","DeliveryStreamDescription","Destinations","DescribeDeliveryStreamInput","DescribeDeliveryStreamOutput","S3DestinationUpdate","ElasticsearchDestinationUpdate","ExtendedS3DestinationUpdate","ListDeliveryStreamsInput","ListDeliveryStreamsOutput","ListTagsForDeliveryStreamInput","ListTagsForDeliveryStreamOutput","_Record","PutRecordInput","PutRecordOutput","ServiceUnavailableException","PutRecordBatchInput","PutRecordBatchResponseEntry","PutRecordBatchOutput","StartDeliveryStreamEncryptionInput","StartDeliveryStreamEncryptionOutput","StopDeliveryStreamEncryptionInput","StopDeliveryStreamEncryptionOutput","TagDeliveryStreamInput","TagDeliveryStreamOutput","UntagDeliveryStreamInput","UntagDeliveryStreamOutput","HttpEndpointDestinationUpdate","RedshiftDestinationUpdate","SplunkDestinationUpdate","UpdateDestinationInput","UpdateDestinationOutput"],"sources":["/Users/yannellym/Desktop/iwantapet/node_modules/@aws-sdk/client-firehose/models/models_0.ts"],"sourcesContent":["import { SENSITIVE_STRING, SmithyException as __SmithyException } from \"@aws-sdk/smithy-client\";\nimport { MetadataBearer as $MetadataBearer } from \"@aws-sdk/types\";\n\n/**\n * <p>Describes hints for the buffering to perform before delivering data to the\n *          destination. These options are treated as hints, and therefore Kinesis Data Firehose might\n *          choose to use different values when it is optimal. The <code>SizeInMBs</code> and\n *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n *          one of them, you must also provide a value for the other.</p>\n */\nexport interface BufferingHints {\n  /**\n   * <p>Buffer incoming data to the specified size, in MiBs, before delivering it to the\n   *          destination. The default value is 5. This parameter is optional but if you specify a value\n   *          for it, you must also specify a value for <code>IntervalInSeconds</code>, and vice\n   *          versa.</p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MiB/sec, the value should be 10 MiB or higher.</p>\n   */\n  SizeInMBs?: number;\n\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering\n   *          it to the destination. The default value is 300. This parameter is optional but if you\n   *          specify a value for it, you must also specify a value for <code>SizeInMBs</code>, and vice\n   *          versa.</p>\n   */\n  IntervalInSeconds?: number;\n}\n\nexport namespace BufferingHints {\n  export const filterSensitiveLog = (obj: BufferingHints): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n */\nexport interface CloudWatchLoggingOptions {\n  /**\n   * <p>Enables or disables CloudWatch logging.</p>\n   */\n  Enabled?: boolean;\n\n  /**\n   * <p>The CloudWatch group name for logging. This value is required if CloudWatch logging\n   *          is enabled.</p>\n   */\n  LogGroupName?: string;\n\n  /**\n   * <p>The CloudWatch log stream name for logging. This value is required if CloudWatch\n   *          logging is enabled.</p>\n   */\n  LogStreamName?: string;\n}\n\nexport namespace CloudWatchLoggingOptions {\n  export const filterSensitiveLog = (obj: CloudWatchLoggingOptions): any => ({\n    ...obj,\n  });\n}\n\nexport enum CompressionFormat {\n  GZIP = \"GZIP\",\n  HADOOP_SNAPPY = \"HADOOP_SNAPPY\",\n  SNAPPY = \"Snappy\",\n  UNCOMPRESSED = \"UNCOMPRESSED\",\n  ZIP = \"ZIP\",\n}\n\n/**\n * <p>Another modification has already happened. Fetch <code>VersionId</code> again and use\n *          it to update the destination.</p>\n */\nexport interface ConcurrentModificationException extends __SmithyException, $MetadataBearer {\n  name: \"ConcurrentModificationException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ConcurrentModificationException {\n  export const filterSensitiveLog = (obj: ConcurrentModificationException): any => ({\n    ...obj,\n  });\n}\n\nexport enum ContentEncoding {\n  GZIP = \"GZIP\",\n  NONE = \"NONE\",\n}\n\n/**\n * <p>Describes a <code>COPY</code> command for Amazon Redshift.</p>\n */\nexport interface CopyCommand {\n  /**\n   * <p>The name of the target table. The table must already exist in the database.</p>\n   */\n  DataTableName: string | undefined;\n\n  /**\n   * <p>A comma-separated list of column names.</p>\n   */\n  DataTableColumns?: string;\n\n  /**\n   * <p>Optional parameters to use with the Amazon Redshift <code>COPY</code> command. For\n   *          more information, see the \"Optional Parameters\" section of <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html\">Amazon Redshift COPY command</a>. Some possible\n   *          examples that would apply to Kinesis Data Firehose are as follows:</p>\n   *          <p>\n   *             <code>delimiter '\\t' lzop;</code> - fields are delimited with \"\\t\" (TAB character) and\n   *          compressed using lzop.</p>\n   *          <p>\n   *             <code>delimiter '|'</code> - fields are delimited with \"|\" (this is the default\n   *          delimiter).</p>\n   *          <p>\n   *             <code>delimiter '|' escape</code> - the delimiter should be escaped.</p>\n   *          <p>\n   *             <code>fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6'</code> -\n   *          fields are fixed width in the source, with each width specified after every column in the\n   *          table.</p>\n   *          <p>\n   *             <code>JSON 's3://mybucket/jsonpaths.txt'</code> - data is in JSON format, and the path\n   *          specified is the format of the data.</p>\n   *          <p>For more examples, see <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html\">Amazon Redshift COPY command\n   *             examples</a>.</p>\n   */\n  CopyOptions?: string;\n}\n\nexport namespace CopyCommand {\n  export const filterSensitiveLog = (obj: CopyCommand): any => ({\n    ...obj,\n  });\n}\n\nexport enum KeyType {\n  AWS_OWNED_CMK = \"AWS_OWNED_CMK\",\n  CUSTOMER_MANAGED_CMK = \"CUSTOMER_MANAGED_CMK\",\n}\n\n/**\n * <p>Specifies the type and Amazon Resource Name (ARN) of the CMK to use for Server-Side\n *          Encryption (SSE). </p>\n */\nexport interface DeliveryStreamEncryptionConfigurationInput {\n  /**\n   * <p>If you set <code>KeyType</code> to <code>CUSTOMER_MANAGED_CMK</code>, you must specify\n   *          the Amazon Resource Name (ARN) of the CMK. If you set <code>KeyType</code> to\n   *             <code>AWS_OWNED_CMK</code>, Kinesis Data Firehose uses a service-account CMK.</p>\n   */\n  KeyARN?: string;\n\n  /**\n   * <p>Indicates the type of customer master key (CMK) to use for encryption. The default\n   *          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys\">Customer Master Keys (CMKs)</a>. When you invoke <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a> with\n   *             <code>KeyType</code> set to CUSTOMER_MANAGED_CMK, Kinesis Data Firehose invokes the\n   *          Amazon KMS operation <a href=\"https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateGrant.html\">CreateGrant</a> to create a grant that allows the Kinesis Data Firehose service to\n   *          use the customer managed CMK to perform encryption and decryption. Kinesis Data Firehose\n   *          manages that grant. </p>\n   *          <p>When you invoke <a>StartDeliveryStreamEncryption</a> to change the CMK for a\n   *          delivery stream that is encrypted with a customer managed CMK, Kinesis Data Firehose\n   *          schedules the grant it had on the old CMK for retirement.</p>\n   *          <p>You can use a CMK of type CUSTOMER_MANAGED_CMK to encrypt up to 500 delivery streams. If\n   *          a <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a>\n   *          operation exceeds this limit, Kinesis Data Firehose throws a\n   *             <code>LimitExceededException</code>. </p>\n   *          <important>\n   *             <p>To encrypt your delivery stream, use symmetric CMKs. Kinesis Data Firehose doesn't\n   *             support asymmetric CMKs. For information about symmetric and asymmetric CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-concepts.html\">About Symmetric and Asymmetric CMKs</a> in the AWS Key Management Service\n   *             developer guide.</p>\n   *          </important>\n   */\n  KeyType: KeyType | string | undefined;\n}\n\nexport namespace DeliveryStreamEncryptionConfigurationInput {\n  export const filterSensitiveLog = (obj: DeliveryStreamEncryptionConfigurationInput): any => ({\n    ...obj,\n  });\n}\n\nexport type DeliveryStreamType = \"DirectPut\" | \"KinesisStreamAsSource\";\n\n/**\n * <p>Describes the buffering to perform before delivering data to the Amazon ES\n *          destination.</p>\n */\nexport interface ElasticsearchBufferingHints {\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering\n   *          it to the destination. The default value is 300 (5 minutes).</p>\n   */\n  IntervalInSeconds?: number;\n\n  /**\n   * <p>Buffer incoming data to the specified size, in MBs, before delivering it to the\n   *          destination. The default value is 5.</p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MB/sec, the value should be 10 MB or higher.</p>\n   */\n  SizeInMBs?: number;\n}\n\nexport namespace ElasticsearchBufferingHints {\n  export const filterSensitiveLog = (obj: ElasticsearchBufferingHints): any => ({\n    ...obj,\n  });\n}\n\nexport type ElasticsearchIndexRotationPeriod = \"NoRotation\" | \"OneDay\" | \"OneHour\" | \"OneMonth\" | \"OneWeek\";\n\nexport enum ProcessorParameterName {\n  BUFFER_INTERVAL_IN_SECONDS = \"BufferIntervalInSeconds\",\n  BUFFER_SIZE_IN_MB = \"BufferSizeInMBs\",\n  LAMBDA_ARN = \"LambdaArn\",\n  LAMBDA_NUMBER_OF_RETRIES = \"NumberOfRetries\",\n  ROLE_ARN = \"RoleArn\",\n}\n\n/**\n * <p>Describes the processor parameter.</p>\n */\nexport interface ProcessorParameter {\n  /**\n   * <p>The name of the parameter.</p>\n   */\n  ParameterName: ProcessorParameterName | string | undefined;\n\n  /**\n   * <p>The parameter value.</p>\n   */\n  ParameterValue: string | undefined;\n}\n\nexport namespace ProcessorParameter {\n  export const filterSensitiveLog = (obj: ProcessorParameter): any => ({\n    ...obj,\n  });\n}\n\nexport type ProcessorType = \"Lambda\";\n\n/**\n * <p>Describes a data processor.</p>\n */\nexport interface Processor {\n  /**\n   * <p>The type of processor.</p>\n   */\n  Type: ProcessorType | string | undefined;\n\n  /**\n   * <p>The processor parameters.</p>\n   */\n  Parameters?: ProcessorParameter[];\n}\n\nexport namespace Processor {\n  export const filterSensitiveLog = (obj: Processor): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes a data processing configuration.</p>\n */\nexport interface ProcessingConfiguration {\n  /**\n   * <p>Enables or disables data processing.</p>\n   */\n  Enabled?: boolean;\n\n  /**\n   * <p>The data processors.</p>\n   */\n  Processors?: Processor[];\n}\n\nexport namespace ProcessingConfiguration {\n  export const filterSensitiveLog = (obj: ProcessingConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Amazon ES.</p>\n */\nexport interface ElasticsearchRetryOptions {\n  /**\n   * <p>After an initial failure to deliver to Amazon ES, the total amount of time during\n   *          which Kinesis Data Firehose retries delivery (including the first attempt). After this time\n   *          has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5\n   *          minutes). A value of 0 (zero) results in no retries.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace ElasticsearchRetryOptions {\n  export const filterSensitiveLog = (obj: ElasticsearchRetryOptions): any => ({\n    ...obj,\n  });\n}\n\nexport type ElasticsearchS3BackupMode = \"AllDocuments\" | \"FailedDocumentsOnly\";\n\n/**\n * <p>Describes an encryption key for a destination in Amazon S3.</p>\n */\nexport interface KMSEncryptionConfig {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the encryption key. Must belong to the same AWS\n   *          Region as the destination Amazon S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  AWSKMSKeyARN: string | undefined;\n}\n\nexport namespace KMSEncryptionConfig {\n  export const filterSensitiveLog = (obj: KMSEncryptionConfig): any => ({\n    ...obj,\n  });\n}\n\nexport type NoEncryptionConfig = \"NoEncryption\";\n\n/**\n * <p>Describes the encryption for a destination in Amazon S3.</p>\n */\nexport interface EncryptionConfiguration {\n  /**\n   * <p>Specifically override existing encryption information to ensure that no encryption is\n   *          used.</p>\n   */\n  NoEncryptionConfig?: NoEncryptionConfig | string;\n\n  /**\n   * <p>The encryption key.</p>\n   */\n  KMSEncryptionConfig?: KMSEncryptionConfig;\n}\n\nexport namespace EncryptionConfiguration {\n  export const filterSensitiveLog = (obj: EncryptionConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the configuration of a destination in Amazon S3.</p>\n */\nexport interface S3DestinationConfiguration {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          for Amazon Redshift destinations because they are not supported by the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace S3DestinationConfiguration {\n  export const filterSensitiveLog = (obj: S3DestinationConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The details of the VPC of the Amazon ES destination.</p>\n */\nexport interface VpcConfiguration {\n  /**\n   * <p>The IDs of the subnets that you want Kinesis Data Firehose to use to create ENIs in the\n   *          VPC of the Amazon ES destination. Make sure that the routing tables and inbound and\n   *          outbound rules allow traffic to flow from the subnets whose IDs are specified here to the\n   *          subnets that have the destination Amazon ES endpoints. Kinesis Data Firehose creates at\n   *          least one ENI in each of the subnets that are specified here. Do not delete or modify these\n   *          ENIs.</p>\n   *          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here\n   *          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to\n   *          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To\n   *          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to\n   *          three ENIs for this delivery stream for each of the subnets specified here. For more\n   *          information about ENI quota, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis\">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>\n   */\n  SubnetIds: string[] | undefined;\n\n  /**\n   * <p>The ARN of the IAM role that you want the delivery stream to use to create endpoints in\n   *          the destination VPC. You can use your existing Kinesis Data Firehose delivery role or you\n   *          can specify a new role. In either case, make sure that the role trusts the Kinesis Data\n   *          Firehose service principal and that it grants the following permissions:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcs</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcAttribute</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSubnets</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSecurityGroups</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeNetworkInterfaces</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterfacePermission</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DeleteNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *          </ul>\n   *          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data\n   *          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a\n   *          degradation in performance.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The IDs of the security groups that you want Kinesis Data Firehose to use when it\n   *          creates ENIs in the VPC of the Amazon ES destination. You can use the same security group\n   *          that the Amazon ES domain uses or different ones. If you specify different security groups\n   *          here, ensure that they allow outbound HTTPS traffic to the Amazon ES domain's security\n   *          group. Also ensure that the Amazon ES domain's security group allows HTTPS traffic from the\n   *          security groups specified here. If you use the same security group for both your delivery\n   *          stream and the Amazon ES domain, make sure the security group inbound rule allows HTTPS\n   *          traffic. For more information about security group rules, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules\">Security group rules</a> in the Amazon VPC documentation.</p>\n   */\n  SecurityGroupIds: string[] | undefined;\n}\n\nexport namespace VpcConfiguration {\n  export const filterSensitiveLog = (obj: VpcConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the configuration of a destination in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationConfiguration {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose\n   *          for calling the Amazon ES Configuration API and for indexing documents. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n   *             Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. The IAM role must have permissions\n   *             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,\n   *          and <code>DescribeElasticsearchDomainConfig</code>after assuming the role specified in\n   *             <b>RoleARN</b>. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>\n   */\n  DomainARN?: string;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Specify either this\n   *             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName: string | undefined;\n\n  /**\n   * <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per\n   *          index. If you try to specify a new type for an existing index that already has another\n   *          type, Kinesis Data Firehose returns an error during run time.</p>\n   *\n   *          <p>For Elasticsearch 7.x, don't specify a <code>TypeName</code>.</p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to the\n   *             <code>IndexName</code> to facilitate the expiration of old data. For more information,\n   *          see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index Rotation for the\n   *             Amazon ES Destination</a>. The default value is<code>OneDay</code>.</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n\n  /**\n   * <p>The buffering options. If no value is specified, the default values for\n   *             <code>ElasticsearchBufferingHints</code> are used.</p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon ES. The default value is 300 (5 minutes).</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When it is set to\n   *             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any documents that could\n   *          not be indexed to the configured Amazon S3 destination, with\n   *             <code>elasticsearch-failed/</code> appended to the key prefix. When set to\n   *             <code>AllDocuments</code>, Kinesis Data Firehose delivers all incoming records to Amazon\n   *          S3, and also writes failed documents with <code>elasticsearch-failed/</code> appended to\n   *          the prefix. For more information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-s3-backup\">Amazon S3 Backup for the\n   *             Amazon ES Destination</a>. Default value is\n   *          <code>FailedDocumentsOnly</code>.</p>\n   *          <p>You can't change this backup mode after you create the delivery stream. </p>\n   */\n  S3BackupMode?: ElasticsearchS3BackupMode | string;\n\n  /**\n   * <p>The configuration for the backup Amazon S3 location.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The details of the VPC of the Amazon ES destination.</p>\n   */\n  VpcConfiguration?: VpcConfiguration;\n}\n\nexport namespace ElasticsearchDestinationConfiguration {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing\n *          data, which means converting it from the JSON format in preparation for serializing it to\n *          the Parquet or ORC format. This is one of two deserializers you can choose, depending on\n *          which one offers the functionality you need. The other option is the OpenX SerDe.</p>\n */\nexport interface HiveJsonSerDe {\n  /**\n   * <p>Indicates how you want Kinesis Data Firehose to parse the date and timestamps that\n   *          may be present in your input data JSON. To specify these format strings, follow the pattern\n   *          syntax of JodaTime's DateTimeFormat format strings. For more information, see <a href=\"https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">Class DateTimeFormat</a>. You can also use the special value <code>millis</code> to\n   *          parse timestamps in epoch milliseconds. If you don't specify a format, Kinesis Data\n   *          Firehose uses <code>java.sql.Timestamp::valueOf</code> by default.</p>\n   */\n  TimestampFormats?: string[];\n}\n\nexport namespace HiveJsonSerDe {\n  export const filterSensitiveLog = (obj: HiveJsonSerDe): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means\n *          converting it from the JSON format in preparation for serializing it to the Parquet or ORC\n *          format. This is one of two deserializers you can choose, depending on which one offers the\n *          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>\n */\nexport interface OpenXJsonSerDe {\n  /**\n   * <p>When set to <code>true</code>, specifies that the names of the keys include dots and\n   *          that you want Kinesis Data Firehose to replace them with underscores. This is useful\n   *          because Apache Hive does not allow dots in column names. For example, if the JSON contains\n   *          a key whose name is \"a.b\", you can define the column name to be \"a_b\" when using this\n   *          option.</p>\n   *          <p>The default is <code>false</code>.</p>\n   */\n  ConvertDotsInJsonKeysToUnderscores?: boolean;\n\n  /**\n   * <p>When set to <code>true</code>, which is the default, Kinesis Data Firehose converts\n   *          JSON keys to lowercase before deserializing them.</p>\n   */\n  CaseInsensitive?: boolean;\n\n  /**\n   * <p>Maps column names to JSON keys that aren't identical to the column names. This is\n   *          useful when the JSON contains keys that are Hive keywords. For example,\n   *             <code>timestamp</code> is a Hive keyword. If you have a JSON key named\n   *             <code>timestamp</code>, set this parameter to <code>{\"ts\": \"timestamp\"}</code> to map\n   *          this key to a column named <code>ts</code>.</p>\n   */\n  ColumnToJsonKeyMappings?: { [key: string]: string };\n}\n\nexport namespace OpenXJsonSerDe {\n  export const filterSensitiveLog = (obj: OpenXJsonSerDe): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The deserializer you want Kinesis Data Firehose to use for converting the input data\n *          from JSON. Kinesis Data Firehose then serializes the data to its final format using the\n *             <a>Serializer</a>. Kinesis Data Firehose supports two types of deserializers:\n *          the <a href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON\">Apache Hive JSON SerDe</a> and the <a href=\"https://github.com/rcongiu/Hive-JSON-Serde\">OpenX JSON SerDe</a>.</p>\n */\nexport interface Deserializer {\n  /**\n   * <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means\n   *          converting it from the JSON format in preparation for serializing it to the Parquet or ORC\n   *          format. This is one of two deserializers you can choose, depending on which one offers the\n   *          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>\n   */\n  OpenXJsonSerDe?: OpenXJsonSerDe;\n\n  /**\n   * <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing\n   *          data, which means converting it from the JSON format in preparation for serializing it to\n   *          the Parquet or ORC format. This is one of two deserializers you can choose, depending on\n   *          which one offers the functionality you need. The other option is the OpenX SerDe.</p>\n   */\n  HiveJsonSerDe?: HiveJsonSerDe;\n}\n\nexport namespace Deserializer {\n  export const filterSensitiveLog = (obj: Deserializer): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Specifies the deserializer you want to use to convert the format of the input data.\n *          This parameter is required if <code>Enabled</code> is set to true.</p>\n */\nexport interface InputFormatConfiguration {\n  /**\n   * <p>Specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe\n   *          or the OpenX JSON SerDe. If both are non-null, the server rejects the request.</p>\n   */\n  Deserializer?: Deserializer;\n}\n\nexport namespace InputFormatConfiguration {\n  export const filterSensitiveLog = (obj: InputFormatConfiguration): any => ({\n    ...obj,\n  });\n}\n\nexport enum OrcCompression {\n  NONE = \"NONE\",\n  SNAPPY = \"SNAPPY\",\n  ZLIB = \"ZLIB\",\n}\n\nexport enum OrcFormatVersion {\n  V0_11 = \"V0_11\",\n  V0_12 = \"V0_12\",\n}\n\n/**\n * <p>A serializer to use for converting data to the ORC format before storing it in Amazon\n *          S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache\n *          ORC</a>.</p>\n */\nexport interface OrcSerDe {\n  /**\n   * <p>The number of bytes in each stripe. The default is 64 MiB and the minimum is 8\n   *          MiB.</p>\n   */\n  StripeSizeBytes?: number;\n\n  /**\n   * <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to\n   *          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the\n   *          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>\n   */\n  BlockSizeBytes?: number;\n\n  /**\n   * <p>The number of rows between index entries. The default is 10,000 and the minimum is\n   *          1,000.</p>\n   */\n  RowIndexStride?: number;\n\n  /**\n   * <p>Set this to <code>true</code> to indicate that you want stripes to be padded to the HDFS\n   *          block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS\n   *          before querying. The default is <code>false</code>.</p>\n   */\n  EnablePadding?: boolean;\n\n  /**\n   * <p>A number between 0 and 1 that defines the tolerance for block padding as a decimal\n   *          fraction of stripe size. The default value is 0.05, which means 5 percent of stripe\n   *          size.</p>\n   *          <p>For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block\n   *          padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB\n   *          block. In such a case, if the available size within the block is more than 3.2 MiB, a new,\n   *          smaller stripe is inserted to fit within that space. This ensures that no stripe crosses\n   *          block boundaries and causes remote reads within a node-local task.</p>\n   *          <p>Kinesis Data Firehose ignores this parameter when <a>OrcSerDe$EnablePadding</a> is <code>false</code>.</p>\n   */\n  PaddingTolerance?: number;\n\n  /**\n   * <p>The compression code to use over data blocks. The default is <code>SNAPPY</code>.</p>\n   */\n  Compression?: OrcCompression | string;\n\n  /**\n   * <p>The column names for which you want Kinesis Data Firehose to create bloom filters. The\n   *          default is <code>null</code>.</p>\n   */\n  BloomFilterColumns?: string[];\n\n  /**\n   * <p>The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the\n   *          Bloom filter. The default value is 0.05, the minimum is 0, and the maximum is 1.</p>\n   */\n  BloomFilterFalsePositiveProbability?: number;\n\n  /**\n   * <p>Represents the fraction of the total number of non-null rows. To turn off dictionary\n   *          encoding, set this fraction to a number that is less than the number of distinct keys in a\n   *          dictionary. To always use dictionary encoding, set this threshold to 1.</p>\n   */\n  DictionaryKeyThreshold?: number;\n\n  /**\n   * <p>The version of the file to write. The possible values are <code>V0_11</code> and\n   *             <code>V0_12</code>. The default is <code>V0_12</code>.</p>\n   */\n  FormatVersion?: OrcFormatVersion | string;\n}\n\nexport namespace OrcSerDe {\n  export const filterSensitiveLog = (obj: OrcSerDe): any => ({\n    ...obj,\n  });\n}\n\nexport enum ParquetCompression {\n  GZIP = \"GZIP\",\n  SNAPPY = \"SNAPPY\",\n  UNCOMPRESSED = \"UNCOMPRESSED\",\n}\n\nexport enum ParquetWriterVersion {\n  V1 = \"V1\",\n  V2 = \"V2\",\n}\n\n/**\n * <p>A serializer to use for converting data to the Parquet format before storing it in\n *          Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache Parquet</a>.</p>\n */\nexport interface ParquetSerDe {\n  /**\n   * <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to\n   *          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the\n   *          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>\n   */\n  BlockSizeBytes?: number;\n\n  /**\n   * <p>The Parquet page size. Column chunks are divided into pages. A page is conceptually an\n   *          indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and\n   *          the default is 1 MiB.</p>\n   */\n  PageSizeBytes?: number;\n\n  /**\n   * <p>The compression code to use over data blocks. The possible values are\n   *             <code>UNCOMPRESSED</code>, <code>SNAPPY</code>, and <code>GZIP</code>, with the default\n   *          being <code>SNAPPY</code>. Use <code>SNAPPY</code> for higher decompression speed. Use\n   *             <code>GZIP</code> if the compression ratio is more important than speed.</p>\n   */\n  Compression?: ParquetCompression | string;\n\n  /**\n   * <p>Indicates whether to enable dictionary compression.</p>\n   */\n  EnableDictionaryCompression?: boolean;\n\n  /**\n   * <p>The maximum amount of padding to apply. This is useful if you intend to copy the data\n   *          from Amazon S3 to HDFS before querying. The default is 0.</p>\n   */\n  MaxPaddingBytes?: number;\n\n  /**\n   * <p>Indicates the version of row format to output. The possible values are <code>V1</code>\n   *          and <code>V2</code>. The default is <code>V1</code>.</p>\n   */\n  WriterVersion?: ParquetWriterVersion | string;\n}\n\nexport namespace ParquetSerDe {\n  export const filterSensitiveLog = (obj: ParquetSerDe): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The serializer that you want Kinesis Data Firehose to use to convert data to the target\n *          format before writing it to Amazon S3. Kinesis Data Firehose supports two types of\n *          serializers: the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html\">ORC SerDe</a> and the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html\">Parquet SerDe</a>.</p>\n */\nexport interface Serializer {\n  /**\n   * <p>A serializer to use for converting data to the Parquet format before storing it in\n   *          Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache Parquet</a>.</p>\n   */\n  ParquetSerDe?: ParquetSerDe;\n\n  /**\n   * <p>A serializer to use for converting data to the ORC format before storing it in Amazon\n   *          S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache\n   *          ORC</a>.</p>\n   */\n  OrcSerDe?: OrcSerDe;\n}\n\nexport namespace Serializer {\n  export const filterSensitiveLog = (obj: Serializer): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the\n *          format of your data before it writes it to Amazon S3. This parameter is required if\n *             <code>Enabled</code> is set to true.</p>\n */\nexport interface OutputFormatConfiguration {\n  /**\n   * <p>Specifies which serializer to use. You can choose either the ORC SerDe or the Parquet\n   *          SerDe. If both are non-null, the server rejects the request.</p>\n   */\n  Serializer?: Serializer;\n}\n\nexport namespace OutputFormatConfiguration {\n  export const filterSensitiveLog = (obj: OutputFormatConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Specifies the schema to which you want Kinesis Data Firehose to configure your data\n *          before it writes it to Amazon S3. This parameter is required if <code>Enabled</code> is set\n *          to true.</p>\n */\nexport interface SchemaConfiguration {\n  /**\n   * <p>The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in\n   *          the same account you use for Kinesis Data Firehose. Cross-account roles aren't\n   *          allowed.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is\n   *          used by default.</p>\n   */\n  CatalogId?: string;\n\n  /**\n   * <p>Specifies the name of the AWS Glue database that contains the schema for the output\n   *          data.</p>\n   */\n  DatabaseName?: string;\n\n  /**\n   * <p>Specifies the AWS Glue table that contains the column information that constitutes your\n   *          data schema.</p>\n   */\n  TableName?: string;\n\n  /**\n   * <p>If you don't specify an AWS Region, the default is the current Region.</p>\n   */\n  Region?: string;\n\n  /**\n   * <p>Specifies the table version for the output data schema. If you don't specify this\n   *          version ID, or if you set it to <code>LATEST</code>, Kinesis Data Firehose uses the most\n   *          recent version. This means that any updates to the table are automatically picked\n   *          up.</p>\n   */\n  VersionId?: string;\n}\n\nexport namespace SchemaConfiguration {\n  export const filterSensitiveLog = (obj: SchemaConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Specifies that you want Kinesis Data Firehose to convert data from the JSON format to\n *          the Parquet or ORC format before writing it to Amazon S3. Kinesis Data Firehose uses the\n *          serializer and deserializer that you specify, in addition to the column information from\n *          the AWS Glue table, to deserialize your input data from JSON and then serialize it to the\n *          Parquet or ORC format. For more information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html\">Kinesis Data Firehose Record Format Conversion</a>.</p>\n */\nexport interface DataFormatConversionConfiguration {\n  /**\n   * <p>Specifies the AWS Glue Data Catalog table that contains the column information. This\n   *          parameter is required if <code>Enabled</code> is set to true.</p>\n   */\n  SchemaConfiguration?: SchemaConfiguration;\n\n  /**\n   * <p>Specifies the deserializer that you want Kinesis Data Firehose to use to convert the\n   *          format of your data from JSON. This parameter is required if <code>Enabled</code> is set to\n   *          true.</p>\n   */\n  InputFormatConfiguration?: InputFormatConfiguration;\n\n  /**\n   * <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the\n   *          format of your data to the Parquet or ORC format. This parameter is required if\n   *             <code>Enabled</code> is set to true.</p>\n   */\n  OutputFormatConfiguration?: OutputFormatConfiguration;\n\n  /**\n   * <p>Defaults to <code>true</code>. Set it to <code>false</code> if you want to disable\n   *          format conversion while preserving the configuration details.</p>\n   */\n  Enabled?: boolean;\n}\n\nexport namespace DataFormatConversionConfiguration {\n  export const filterSensitiveLog = (obj: DataFormatConversionConfiguration): any => ({\n    ...obj,\n  });\n}\n\nexport type S3BackupMode = \"Disabled\" | \"Enabled\";\n\n/**\n * <p>Describes the configuration of a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationConfiguration {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *          UNCOMPRESSED.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to\n   *          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the\n   *          delivery stream to disable it. </p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n}\n\nexport namespace ExtendedS3DestinationConfiguration {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the buffering options that can be applied before data is delivered to the HTTP\n *          endpoint destination. Kinesis Data Firehose treats these options as hints, and it might\n *          choose to use more optimal values. The <code>SizeInMBs</code> and\n *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n *          one of them, you must also provide a value for the other. </p>\n */\nexport interface HttpEndpointBufferingHints {\n  /**\n   * <p>Buffer incoming data to the specified size, in MBs, before delivering it to the\n   *          destination. The default value is 5. </p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MB/sec, the value should be 10 MB or higher. </p>\n   */\n  SizeInMBs?: number;\n\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering it\n   *          to the destination. The default value is 300 (5 minutes). </p>\n   */\n  IntervalInSeconds?: number;\n}\n\nexport namespace HttpEndpointBufferingHints {\n  export const filterSensitiveLog = (obj: HttpEndpointBufferingHints): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the configuration of the HTTP endpoint to which Kinesis Firehose delivers\n *          data.</p>\n */\nexport interface HttpEndpointConfiguration {\n  /**\n   * <p>The URL of the HTTP endpoint selected as the destination.</p>\n   */\n  Url: string | undefined;\n\n  /**\n   * <p>The name of the HTTP endpoint selected as the destination.</p>\n   */\n  Name?: string;\n\n  /**\n   * <p>The access key required for Kinesis Firehose to authenticate with the HTTP endpoint\n   *          selected as the destination.</p>\n   */\n  AccessKey?: string;\n}\n\nexport namespace HttpEndpointConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointConfiguration): any => ({\n    ...obj,\n    ...(obj.Url && { Url: SENSITIVE_STRING }),\n    ...(obj.AccessKey && { AccessKey: SENSITIVE_STRING }),\n  });\n}\n\n/**\n * <p>Describes the metadata that's delivered to the specified HTTP endpoint\n *          destination.</p>\n */\nexport interface HttpEndpointCommonAttribute {\n  /**\n   * <p>The name of the HTTP endpoint common attribute.</p>\n   */\n  AttributeName: string | undefined;\n\n  /**\n   * <p>The value of the HTTP endpoint common attribute.</p>\n   */\n  AttributeValue: string | undefined;\n}\n\nexport namespace HttpEndpointCommonAttribute {\n  export const filterSensitiveLog = (obj: HttpEndpointCommonAttribute): any => ({\n    ...obj,\n    ...(obj.AttributeName && { AttributeName: SENSITIVE_STRING }),\n    ...(obj.AttributeValue && { AttributeValue: SENSITIVE_STRING }),\n  });\n}\n\n/**\n * <p>The configuration of the HTTP endpoint request.</p>\n */\nexport interface HttpEndpointRequestConfiguration {\n  /**\n   * <p>Kinesis Data Firehose uses the content encoding to compress the body of a request before\n   *          sending the request to the destination. For more information, see <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding\">Content-Encoding</a> in MDN Web Docs, the official Mozilla documentation.</p>\n   */\n  ContentEncoding?: ContentEncoding | string;\n\n  /**\n   * <p>Describes the metadata sent to the HTTP endpoint destination.</p>\n   */\n  CommonAttributes?: HttpEndpointCommonAttribute[];\n}\n\nexport namespace HttpEndpointRequestConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointRequestConfiguration): any => ({\n    ...obj,\n    ...(obj.CommonAttributes && {\n      CommonAttributes: obj.CommonAttributes.map((item) => HttpEndpointCommonAttribute.filterSensitiveLog(item)),\n    }),\n  });\n}\n\n/**\n * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n *          receipt from the specified HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointRetryOptions {\n  /**\n   * <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration\n   *          starts after the initial attempt to send data to the custom destination via HTTPS endpoint\n   *          fails. It doesn't include the periods during which Kinesis Data Firehose waits for\n   *          acknowledgment from the specified destination after each attempt. </p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace HttpEndpointRetryOptions {\n  export const filterSensitiveLog = (obj: HttpEndpointRetryOptions): any => ({\n    ...obj,\n  });\n}\n\nexport type HttpEndpointS3BackupMode = \"AllData\" | \"FailedDataOnly\";\n\n/**\n * <p>Describes the configuration of the HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationConfiguration {\n  /**\n   * <p>The configuration of the HTTP endpoint selected as the destination.</p>\n   */\n  EndpointConfiguration: HttpEndpointConfiguration | undefined;\n\n  /**\n   * <p>The buffering options that can be used before data is delivered to the specified\n   *          destination. Kinesis Data Firehose treats these options as hints, and it might choose to\n   *          use more optimal values. The <code>SizeInMBs</code> and <code>IntervalInSeconds</code>\n   *          parameters are optional. However, if you specify a value for one of them, you must also\n   *          provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The configuration of the requeste sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Data Firehose delivers\n   *          to the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or\n   *          only the documents that Kinesis Data Firehose could not deliver to the specified HTTP\n   *          endpoint destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes the configuration of a destination in Amazon S3.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n}\n\nexport namespace HttpEndpointDestinationConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationConfiguration): any => ({\n    ...obj,\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n  });\n}\n\n/**\n * <p>The stream and role Amazon Resource Names (ARNs) for a Kinesis data stream used as\n *          the source for a delivery stream.</p>\n */\nexport interface KinesisStreamSourceConfiguration {\n  /**\n   * <p>The ARN of the source Kinesis data stream. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon Kinesis Data Streams ARN Format</a>.</p>\n   */\n  KinesisStreamARN: string | undefined;\n\n  /**\n   * <p>The ARN of the role that provides access to the source Kinesis data stream. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS Identity and Access Management (IAM) ARN Format</a>.</p>\n   */\n  RoleARN: string | undefined;\n}\n\nexport namespace KinesisStreamSourceConfiguration {\n  export const filterSensitiveLog = (obj: KinesisStreamSourceConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Amazon Redshift.</p>\n */\nexport interface RedshiftRetryOptions {\n  /**\n   * <p>The length of time during which Kinesis Data Firehose retries delivery after a\n   *          failure, starting from the initial request and including the first attempt. The default\n   *          value is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry if the value of\n   *             <code>DurationInSeconds</code> is 0 (zero) or if the first delivery attempt takes longer\n   *          than the current value.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace RedshiftRetryOptions {\n  export const filterSensitiveLog = (obj: RedshiftRetryOptions): any => ({\n    ...obj,\n  });\n}\n\nexport type RedshiftS3BackupMode = \"Disabled\" | \"Enabled\";\n\n/**\n * <p>Describes the configuration of a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationConfiguration {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL: string | undefined;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand: CopyCommand | undefined;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username: string | undefined;\n\n  /**\n   * <p>The user password.</p>\n   */\n  Password: string | undefined;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The configuration for the intermediate Amazon S3 location from which Amazon Redshift\n   *          obtains data. Restrictions are described in the topic for <a>CreateDeliveryStream</a>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          in <code>RedshiftDestinationConfiguration.S3Configuration</code> because the Amazon\n   *          Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't support these\n   *          compression formats.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to\n   *          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the\n   *          delivery stream to disable it. </p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace RedshiftDestinationConfiguration {\n  export const filterSensitiveLog = (obj: RedshiftDestinationConfiguration): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n    ...(obj.Password && { Password: SENSITIVE_STRING }),\n  });\n}\n\nexport type HECEndpointType = \"Event\" | \"Raw\";\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Splunk, or if it doesn't receive an acknowledgment from Splunk.</p>\n */\nexport interface SplunkRetryOptions {\n  /**\n   * <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration\n   *          starts after the initial attempt to send data to Splunk fails. It doesn't include the\n   *          periods during which Kinesis Data Firehose waits for acknowledgment from Splunk after each\n   *          attempt.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace SplunkRetryOptions {\n  export const filterSensitiveLog = (obj: SplunkRetryOptions): any => ({\n    ...obj,\n  });\n}\n\nexport type SplunkS3BackupMode = \"AllEvents\" | \"FailedEventsOnly\";\n\n/**\n * <p>Describes the configuration of a destination in Splunk.</p>\n */\nexport interface SplunkDestinationConfiguration {\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint: string | undefined;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType: HECEndpointType | string | undefined;\n\n  /**\n   * <p>This is a GUID that you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken: string | undefined;\n\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose\n   *          either tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk,\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When set to\n   *             <code>FailedEventsOnly</code>, Kinesis Data Firehose writes any data that could not be\n   *          indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>\n   *          <p>You can update this backup mode from <code>FailedEventsOnly</code> to\n   *             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to\n   *             <code>FailedEventsOnly</code>.</p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n\n  /**\n   * <p>The configuration for the backup Amazon S3 location.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace SplunkDestinationConfiguration {\n  export const filterSensitiveLog = (obj: SplunkDestinationConfiguration): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Metadata that you can assign to a delivery stream, consisting of a key-value\n *          pair.</p>\n */\nexport interface Tag {\n  /**\n   * <p>A unique identifier for the tag. Maximum length: 128 characters. Valid characters:\n   *          Unicode letters, digits, white space, _ . / = + - % @</p>\n   */\n  Key: string | undefined;\n\n  /**\n   * <p>An optional string, which you can use to describe or define the tag. Maximum length:\n   *          256 characters. Valid characters: Unicode letters, digits, white space, _ . / = + - %\n   *          @</p>\n   */\n  Value?: string;\n}\n\nexport namespace Tag {\n  export const filterSensitiveLog = (obj: Tag): any => ({\n    ...obj,\n  });\n}\n\nexport interface CreateDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream. This name must be unique per AWS account in the same\n   *          AWS Region. If the delivery streams are in different accounts or different Regions, you can\n   *          have multiple delivery streams with the same name.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The delivery stream type. This parameter can be one of the following\n   *          values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   */\n  DeliveryStreamType?: DeliveryStreamType | string;\n\n  /**\n   * <p>When a Kinesis data stream is used as the source for the delivery stream, a <a>KinesisStreamSourceConfiguration</a> containing the Kinesis data stream Amazon\n   *          Resource Name (ARN) and the role ARN for the source stream.</p>\n   */\n  KinesisStreamSourceConfiguration?: KinesisStreamSourceConfiguration;\n\n  /**\n   * <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for\n   *          Server-Side Encryption (SSE).</p>\n   */\n  DeliveryStreamEncryptionConfigurationInput?: DeliveryStreamEncryptionConfigurationInput;\n\n  /**\n   * @deprecated\n   *\n   * <p>[Deprecated]\n   *          The destination in Amazon S3. You can specify only one destination.</p>\n   */\n  S3DestinationConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The destination in Amazon S3. You can specify only one destination.</p>\n   */\n  ExtendedS3DestinationConfiguration?: ExtendedS3DestinationConfiguration;\n\n  /**\n   * <p>The destination in Amazon Redshift. You can specify only one destination.</p>\n   */\n  RedshiftDestinationConfiguration?: RedshiftDestinationConfiguration;\n\n  /**\n   * <p>The destination in Amazon ES. You can specify only one destination.</p>\n   */\n  ElasticsearchDestinationConfiguration?: ElasticsearchDestinationConfiguration;\n\n  /**\n   * <p>The destination in Splunk. You can specify only one destination.</p>\n   */\n  SplunkDestinationConfiguration?: SplunkDestinationConfiguration;\n\n  /**\n   * <p>Enables configuring Kinesis Firehose to deliver data to any HTTP endpoint destination.\n   *          You can specify only one destination.</p>\n   */\n  HttpEndpointDestinationConfiguration?: HttpEndpointDestinationConfiguration;\n\n  /**\n   * <p>A set of tags to assign to the delivery stream. A tag is a key-value pair that you can\n   *          define and assign to AWS resources. Tags are metadata. For example, you can add friendly\n   *          names and descriptions or other types of information that can help you distinguish the\n   *          delivery stream. For more information about tags, see <a href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\">Using Cost Allocation Tags</a> in the AWS Billing and Cost Management User\n   *          Guide.</p>\n   *\n   *          <p>You can specify up to 50 tags when creating a delivery stream.</p>\n   */\n  Tags?: Tag[];\n}\n\nexport namespace CreateDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: CreateDeliveryStreamInput): any => ({\n    ...obj,\n    ...(obj.RedshiftDestinationConfiguration && {\n      RedshiftDestinationConfiguration: RedshiftDestinationConfiguration.filterSensitiveLog(\n        obj.RedshiftDestinationConfiguration\n      ),\n    }),\n    ...(obj.HttpEndpointDestinationConfiguration && {\n      HttpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration.filterSensitiveLog(\n        obj.HttpEndpointDestinationConfiguration\n      ),\n    }),\n  });\n}\n\nexport interface CreateDeliveryStreamOutput {\n  /**\n   * <p>The ARN of the delivery stream.</p>\n   */\n  DeliveryStreamARN?: string;\n}\n\nexport namespace CreateDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: CreateDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The specified input parameter has a value that is not valid.</p>\n */\nexport interface InvalidArgumentException extends __SmithyException, $MetadataBearer {\n  name: \"InvalidArgumentException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace InvalidArgumentException {\n  export const filterSensitiveLog = (obj: InvalidArgumentException): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Kinesis Data Firehose throws this exception when an attempt to put records or to start\n *          or stop delivery stream encryption fails. This happens when the KMS service throws one of\n *          the following exception types: <code>AccessDeniedException</code>,\n *             <code>InvalidStateException</code>, <code>DisabledException</code>, or\n *             <code>NotFoundException</code>.</p>\n */\nexport interface InvalidKMSResourceException extends __SmithyException, $MetadataBearer {\n  name: \"InvalidKMSResourceException\";\n  $fault: \"client\";\n  code?: string;\n  message?: string;\n}\n\nexport namespace InvalidKMSResourceException {\n  export const filterSensitiveLog = (obj: InvalidKMSResourceException): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>You have already reached the limit for a requested resource.</p>\n */\nexport interface LimitExceededException extends __SmithyException, $MetadataBearer {\n  name: \"LimitExceededException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace LimitExceededException {\n  export const filterSensitiveLog = (obj: LimitExceededException): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The resource is already in use and not available for this operation.</p>\n */\nexport interface ResourceInUseException extends __SmithyException, $MetadataBearer {\n  name: \"ResourceInUseException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ResourceInUseException {\n  export const filterSensitiveLog = (obj: ResourceInUseException): any => ({\n    ...obj,\n  });\n}\n\nexport interface DeleteDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Set this to true if you want to delete the delivery stream even if Kinesis Data Firehose\n   *          is unable to retire the grant for the CMK. Kinesis Data Firehose might be unable to retire\n   *          the grant due to a customer error, such as when the CMK or the grant are in an invalid\n   *          state. If you force deletion, you can then use the <a href=\"https://docs.aws.amazon.com/kms/latest/APIReference/API_RevokeGrant.html\">RevokeGrant</a> operation to revoke the grant you gave to Kinesis Data Firehose. If\n   *          a failure to retire the grant happens due to an AWS KMS issue, Kinesis Data Firehose keeps\n   *          retrying the delete operation.</p>\n   *          <p>The default value is false.</p>\n   */\n  AllowForceDelete?: boolean;\n}\n\nexport namespace DeleteDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: DeleteDeliveryStreamInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface DeleteDeliveryStreamOutput {}\n\nexport namespace DeleteDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: DeleteDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The specified resource could not be found.</p>\n */\nexport interface ResourceNotFoundException extends __SmithyException, $MetadataBearer {\n  name: \"ResourceNotFoundException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ResourceNotFoundException {\n  export const filterSensitiveLog = (obj: ResourceNotFoundException): any => ({\n    ...obj,\n  });\n}\n\nexport enum DeliveryStreamFailureType {\n  CREATE_ENI_FAILED = \"CREATE_ENI_FAILED\",\n  CREATE_KMS_GRANT_FAILED = \"CREATE_KMS_GRANT_FAILED\",\n  DELETE_ENI_FAILED = \"DELETE_ENI_FAILED\",\n  DISABLED_KMS_KEY = \"DISABLED_KMS_KEY\",\n  ENI_ACCESS_DENIED = \"ENI_ACCESS_DENIED\",\n  INVALID_KMS_KEY = \"INVALID_KMS_KEY\",\n  KMS_ACCESS_DENIED = \"KMS_ACCESS_DENIED\",\n  KMS_KEY_NOT_FOUND = \"KMS_KEY_NOT_FOUND\",\n  KMS_OPT_IN_REQUIRED = \"KMS_OPT_IN_REQUIRED\",\n  RETIRE_KMS_GRANT_FAILED = \"RETIRE_KMS_GRANT_FAILED\",\n  SECURITY_GROUP_ACCESS_DENIED = \"SECURITY_GROUP_ACCESS_DENIED\",\n  SECURITY_GROUP_NOT_FOUND = \"SECURITY_GROUP_NOT_FOUND\",\n  SUBNET_ACCESS_DENIED = \"SUBNET_ACCESS_DENIED\",\n  SUBNET_NOT_FOUND = \"SUBNET_NOT_FOUND\",\n  UNKNOWN_ERROR = \"UNKNOWN_ERROR\",\n}\n\n/**\n * <p>Provides details in case one of the following operations fails due to an error related\n *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n */\nexport interface FailureDescription {\n  /**\n   * <p>The type of error that caused the failure.</p>\n   */\n  Type: DeliveryStreamFailureType | string | undefined;\n\n  /**\n   * <p>A message providing details about the error that caused the failure.</p>\n   */\n  Details: string | undefined;\n}\n\nexport namespace FailureDescription {\n  export const filterSensitiveLog = (obj: FailureDescription): any => ({\n    ...obj,\n  });\n}\n\nexport enum DeliveryStreamEncryptionStatus {\n  DISABLED = \"DISABLED\",\n  DISABLING = \"DISABLING\",\n  DISABLING_FAILED = \"DISABLING_FAILED\",\n  ENABLED = \"ENABLED\",\n  ENABLING = \"ENABLING\",\n  ENABLING_FAILED = \"ENABLING_FAILED\",\n}\n\n/**\n * <p>Contains information about the server-side encryption (SSE) status for the delivery\n *          stream, the type customer master key (CMK) in use, if any, and the ARN of the CMK. You can\n *          get <code>DeliveryStreamEncryptionConfiguration</code> by invoking the <a>DescribeDeliveryStream</a> operation. </p>\n */\nexport interface DeliveryStreamEncryptionConfiguration {\n  /**\n   * <p>If <code>KeyType</code> is <code>CUSTOMER_MANAGED_CMK</code>, this field contains the\n   *          ARN of the customer managed CMK. If <code>KeyType</code> is <code>AWS_OWNED_CMK</code>,\n   *             <code>DeliveryStreamEncryptionConfiguration</code> doesn't contain a value for\n   *             <code>KeyARN</code>.</p>\n   */\n  KeyARN?: string;\n\n  /**\n   * <p>Indicates the type of customer master key (CMK) that is used for encryption. The default\n   *          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys\">Customer Master Keys (CMKs)</a>.</p>\n   */\n  KeyType?: KeyType | string;\n\n  /**\n   * <p>This is the server-side encryption (SSE) status for the delivery stream. For a full\n   *          description of the different values of this status, see <a>StartDeliveryStreamEncryption</a> and <a>StopDeliveryStreamEncryption</a>. If this status is <code>ENABLING_FAILED</code>\n   *          or <code>DISABLING_FAILED</code>, it is the status of the most recent attempt to enable or\n   *          disable SSE, respectively.</p>\n   */\n  Status?: DeliveryStreamEncryptionStatus | string;\n\n  /**\n   * <p>Provides details in case one of the following operations fails due to an error related\n   *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n   *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n   */\n  FailureDescription?: FailureDescription;\n}\n\nexport namespace DeliveryStreamEncryptionConfiguration {\n  export const filterSensitiveLog = (obj: DeliveryStreamEncryptionConfiguration): any => ({\n    ...obj,\n  });\n}\n\nexport enum DeliveryStreamStatus {\n  ACTIVE = \"ACTIVE\",\n  CREATING = \"CREATING\",\n  CREATING_FAILED = \"CREATING_FAILED\",\n  DELETING = \"DELETING\",\n  DELETING_FAILED = \"DELETING_FAILED\",\n}\n\n/**\n * <p>Describes a destination in Amazon S3.</p>\n */\nexport interface S3DestinationDescription {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints: BufferingHints | undefined;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   */\n  CompressionFormat: CompressionFormat | string | undefined;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration: EncryptionConfiguration | undefined;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace S3DestinationDescription {\n  export const filterSensitiveLog = (obj: S3DestinationDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The details of the VPC of the Amazon ES destination.</p>\n */\nexport interface VpcConfigurationDescription {\n  /**\n   * <p>The IDs of the subnets that Kinesis Data Firehose uses to create ENIs in the VPC of the\n   *          Amazon ES destination. Make sure that the routing tables and inbound and outbound rules\n   *          allow traffic to flow from the subnets whose IDs are specified here to the subnets that\n   *          have the destination Amazon ES endpoints. Kinesis Data Firehose creates at least one ENI in\n   *          each of the subnets that are specified here. Do not delete or modify these ENIs.</p>\n   *          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here\n   *          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to\n   *          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To\n   *          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to\n   *          three ENIs for this delivery stream for each of the subnets specified here. For more\n   *          information about ENI quota, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis\">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>\n   */\n  SubnetIds: string[] | undefined;\n\n  /**\n   * <p>The ARN of the IAM role that the delivery stream uses to create endpoints in the\n   *          destination VPC. You can use your existing Kinesis Data Firehose delivery role or you can\n   *          specify a new role. In either case, make sure that the role trusts the Kinesis Data\n   *          Firehose service principal and that it grants the following permissions:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcs</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcAttribute</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSubnets</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSecurityGroups</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeNetworkInterfaces</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterfacePermission</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DeleteNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *          </ul>\n   *          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data\n   *          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a\n   *          degradation in performance.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The IDs of the security groups that Kinesis Data Firehose uses when it creates ENIs in\n   *          the VPC of the Amazon ES destination. You can use the same security group that the Amazon\n   *          ES domain uses or different ones. If you specify different security groups, ensure that\n   *          they allow outbound HTTPS traffic to the Amazon ES domain's security group. Also ensure\n   *          that the Amazon ES domain's security group allows HTTPS traffic from the security groups\n   *          specified here. If you use the same security group for both your delivery stream and the\n   *          Amazon ES domain, make sure the security group inbound rule allows HTTPS traffic. For more\n   *          information about security group rules, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules\">Security group rules</a> in the Amazon VPC documentation.</p>\n   */\n  SecurityGroupIds: string[] | undefined;\n\n  /**\n   * <p>The ID of the Amazon ES destination's VPC.</p>\n   */\n  VpcId: string | undefined;\n}\n\nexport namespace VpcConfigurationDescription {\n  export const filterSensitiveLog = (obj: VpcConfigurationDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The destination description in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationDescription {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Kinesis Data Firehose uses either <code>ClusterEndpoint</code> or <code>DomainARN</code>\n   *          to send data to Amazon ES.</p>\n   */\n  DomainARN?: string;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Kinesis Data Firehose uses\n   *          either this <code>ClusterEndpoint</code> or the <code>DomainARN</code> field to send data\n   *          to Amazon ES.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName?: string;\n\n  /**\n   * <p>The Elasticsearch type name. This applies to Elasticsearch 6.x and lower versions.\n   *          For Elasticsearch 7.x, there's no value for <code>TypeName</code>.</p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The Elasticsearch index rotation period</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n\n  /**\n   * <p>The buffering options.</p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The Amazon ES retry options.</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: ElasticsearchS3BackupMode | string;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The details of the VPC of the Amazon ES destination.</p>\n   */\n  VpcConfigurationDescription?: VpcConfigurationDescription;\n}\n\nexport namespace ElasticsearchDestinationDescription {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationDescription {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints: BufferingHints | undefined;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   */\n  CompressionFormat: CompressionFormat | string | undefined;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration: EncryptionConfiguration | undefined;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n}\n\nexport namespace ExtendedS3DestinationDescription {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the HTTP endpoint selected as the destination. </p>\n */\nexport interface HttpEndpointDescription {\n  /**\n   * <p>The URL of the HTTP endpoint selected as the destination.</p>\n   */\n  Url?: string;\n\n  /**\n   * <p>The name of the HTTP endpoint selected as the destination.</p>\n   */\n  Name?: string;\n}\n\nexport namespace HttpEndpointDescription {\n  export const filterSensitiveLog = (obj: HttpEndpointDescription): any => ({\n    ...obj,\n    ...(obj.Url && { Url: SENSITIVE_STRING }),\n  });\n}\n\n/**\n * <p>Describes the HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationDescription {\n  /**\n   * <p>The configuration of the specified HTTP endpoint destination.</p>\n   */\n  EndpointConfiguration?: HttpEndpointDescription;\n\n  /**\n   * <p>Describes buffering options that can be applied to the data before it is delivered to\n   *          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it\n   *          might choose to use more optimal values. The <code>SizeInMBs</code> and\n   *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n   *          one of them, you must also provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The configuration of request sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to\n   *          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only\n   *          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint\n   *          destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes a destination in Amazon S3.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n}\n\nexport namespace HttpEndpointDestinationDescription {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationDescription): any => ({\n    ...obj,\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointDescription.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n  });\n}\n\n/**\n * <p>Describes a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationDescription {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL: string | undefined;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand: CopyCommand | undefined;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username: string | undefined;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3DestinationDescription: S3DestinationDescription | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace RedshiftDestinationDescription {\n  export const filterSensitiveLog = (obj: RedshiftDestinationDescription): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n  });\n}\n\n/**\n * <p>Describes a destination in Splunk.</p>\n */\nexport interface SplunkDestinationDescription {\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint?: string;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType?: HECEndpointType | string;\n\n  /**\n   * <p>A GUID you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken?: string;\n\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose\n   *          either tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When set to\n   *             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could not\n   *          be indexed to the configured Amazon S3 destination. When set to <code>AllDocuments</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. Default value is <code>FailedDocumentsOnly</code>. </p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n\n  /**\n   * <p>The Amazon S3 destination.></p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace SplunkDestinationDescription {\n  export const filterSensitiveLog = (obj: SplunkDestinationDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes the destination for a delivery stream.</p>\n */\nexport interface DestinationDescription {\n  /**\n   * <p>The ID of the destination.</p>\n   */\n  DestinationId: string | undefined;\n\n  /**\n   * <p>[Deprecated] The destination in Amazon S3.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The destination in Amazon S3.</p>\n   */\n  ExtendedS3DestinationDescription?: ExtendedS3DestinationDescription;\n\n  /**\n   * <p>The destination in Amazon Redshift.</p>\n   */\n  RedshiftDestinationDescription?: RedshiftDestinationDescription;\n\n  /**\n   * <p>The destination in Amazon ES.</p>\n   */\n  ElasticsearchDestinationDescription?: ElasticsearchDestinationDescription;\n\n  /**\n   * <p>The destination in Splunk.</p>\n   */\n  SplunkDestinationDescription?: SplunkDestinationDescription;\n\n  /**\n   * <p>Describes the specified HTTP endpoint destination.</p>\n   */\n  HttpEndpointDestinationDescription?: HttpEndpointDestinationDescription;\n}\n\nexport namespace DestinationDescription {\n  export const filterSensitiveLog = (obj: DestinationDescription): any => ({\n    ...obj,\n    ...(obj.RedshiftDestinationDescription && {\n      RedshiftDestinationDescription: RedshiftDestinationDescription.filterSensitiveLog(\n        obj.RedshiftDestinationDescription\n      ),\n    }),\n    ...(obj.HttpEndpointDestinationDescription && {\n      HttpEndpointDestinationDescription: HttpEndpointDestinationDescription.filterSensitiveLog(\n        obj.HttpEndpointDestinationDescription\n      ),\n    }),\n  });\n}\n\n/**\n * <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose\n *          delivery stream.</p>\n */\nexport interface KinesisStreamSourceDescription {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the source Kinesis data stream. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon Kinesis Data Streams ARN Format</a>.</p>\n   */\n  KinesisStreamARN?: string;\n\n  /**\n   * <p>The ARN of the role used by the source Kinesis data stream. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS Identity and Access Management (IAM) ARN Format</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Kinesis Data Firehose starts retrieving records from the Kinesis data stream starting\n   *          with this timestamp.</p>\n   */\n  DeliveryStartTimestamp?: Date;\n}\n\nexport namespace KinesisStreamSourceDescription {\n  export const filterSensitiveLog = (obj: KinesisStreamSourceDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose\n *          delivery stream.</p>\n */\nexport interface SourceDescription {\n  /**\n   * <p>The <a>KinesisStreamSourceDescription</a> value for the source Kinesis\n   *          data stream.</p>\n   */\n  KinesisStreamSourceDescription?: KinesisStreamSourceDescription;\n}\n\nexport namespace SourceDescription {\n  export const filterSensitiveLog = (obj: SourceDescription): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Contains information about a delivery stream.</p>\n */\nexport interface DeliveryStreamDescription {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the delivery stream. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  DeliveryStreamARN: string | undefined;\n\n  /**\n   * <p>The status of the delivery stream. If the status of a delivery stream is\n   *             <code>CREATING_FAILED</code>, this status doesn't change, and you can't invoke\n   *             <code>CreateDeliveryStream</code> again on it. However, you can invoke the <a>DeleteDeliveryStream</a> operation to delete it.</p>\n   */\n  DeliveryStreamStatus: DeliveryStreamStatus | string | undefined;\n\n  /**\n   * <p>Provides details in case one of the following operations fails due to an error related\n   *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n   *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n   */\n  FailureDescription?: FailureDescription;\n\n  /**\n   * <p>Indicates the server-side encryption (SSE) status for the delivery stream.</p>\n   */\n  DeliveryStreamEncryptionConfiguration?: DeliveryStreamEncryptionConfiguration;\n\n  /**\n   * <p>The delivery stream type. This can be one of the following values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   */\n  DeliveryStreamType: DeliveryStreamType | string | undefined;\n\n  /**\n   * <p>Each time the destination is updated for a delivery stream, the version ID is\n   *          changed, and the current version ID is required when updating the destination. This is so\n   *          that the service knows it is applying the changes to the correct version of the delivery\n   *          stream.</p>\n   */\n  VersionId: string | undefined;\n\n  /**\n   * <p>The date and time that the delivery stream was created.</p>\n   */\n  CreateTimestamp?: Date;\n\n  /**\n   * <p>The date and time that the delivery stream was last updated.</p>\n   */\n  LastUpdateTimestamp?: Date;\n\n  /**\n   * <p>If the <code>DeliveryStreamType</code> parameter is\n   *             <code>KinesisStreamAsSource</code>, a <a>SourceDescription</a> object\n   *          describing the source Kinesis data stream.</p>\n   */\n  Source?: SourceDescription;\n\n  /**\n   * <p>The destinations.</p>\n   */\n  Destinations: DestinationDescription[] | undefined;\n\n  /**\n   * <p>Indicates whether there are more destinations available to list.</p>\n   */\n  HasMoreDestinations: boolean | undefined;\n}\n\nexport namespace DeliveryStreamDescription {\n  export const filterSensitiveLog = (obj: DeliveryStreamDescription): any => ({\n    ...obj,\n    ...(obj.Destinations && {\n      Destinations: obj.Destinations.map((item) => DestinationDescription.filterSensitiveLog(item)),\n    }),\n  });\n}\n\nexport interface DescribeDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The limit on the number of destinations to return. You can have one destination per\n   *          delivery stream.</p>\n   */\n  Limit?: number;\n\n  /**\n   * <p>The ID of the destination to start returning the destination information. Kinesis\n   *          Data Firehose supports one destination per delivery stream.</p>\n   */\n  ExclusiveStartDestinationId?: string;\n}\n\nexport namespace DescribeDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: DescribeDeliveryStreamInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface DescribeDeliveryStreamOutput {\n  /**\n   * <p>Information about the delivery stream.</p>\n   */\n  DeliveryStreamDescription: DeliveryStreamDescription | undefined;\n}\n\nexport namespace DescribeDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: DescribeDeliveryStreamOutput): any => ({\n    ...obj,\n    ...(obj.DeliveryStreamDescription && {\n      DeliveryStreamDescription: DeliveryStreamDescription.filterSensitiveLog(obj.DeliveryStreamDescription),\n    }),\n  });\n}\n\n/**\n * <p>Describes an update for a destination in Amazon S3.</p>\n */\nexport interface S3DestinationUpdate {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN?: string;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          for Amazon Redshift destinations because they are not supported by the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace S3DestinationUpdate {\n  export const filterSensitiveLog = (obj: S3DestinationUpdate): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes an update for a destination in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationUpdate {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose\n   *          for calling the Amazon ES Configuration API and for indexing documents. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n   *             Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. The IAM role must have permissions\n   *             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,\n   *          and <code>DescribeElasticsearchDomainConfig</code>after assuming the IAM role specified in\n   *             <code>RoleARN</code>. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>\n   */\n  DomainARN?: string;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Specify either this\n   *             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName?: string;\n\n  /**\n   * <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per\n   *          index. If you try to specify a new type for an existing index that already has another\n   *          type, Kinesis Data Firehose returns an error during runtime.</p>\n   *\n   *          <p>If you upgrade Elasticsearch from 6.x to 7.x and dont update your delivery stream,\n   *          Kinesis Data Firehose still delivers data to Elasticsearch with the old index name and type\n   *          name. If you want to update your delivery stream with a new index name, provide an empty\n   *          string for <code>TypeName</code>. </p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to\n   *             <code>IndexName</code> to facilitate the expiration of old data. For more information,\n   *          see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index Rotation for the\n   *             Amazon ES Destination</a>. Default value is<code>OneDay</code>.</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n\n  /**\n   * <p>The buffering options. If no value is specified,\n   *             <code>ElasticsearchBufferingHints</code> object default values are used. </p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon ES. The default value is 300 (5 minutes).</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace ElasticsearchDestinationUpdate {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationUpdate): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Describes an update for a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationUpdate {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN?: string;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>. </p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If\n   *          backup is enabled, you can't update the delivery stream to disable it. </p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n\n  /**\n   * <p>The Amazon S3 destination for backup.</p>\n   */\n  S3BackupUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n}\n\nexport namespace ExtendedS3DestinationUpdate {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationUpdate): any => ({\n    ...obj,\n  });\n}\n\nexport interface ListDeliveryStreamsInput {\n  /**\n   * <p>The maximum number of delivery streams to list. The default value is 10.</p>\n   */\n  Limit?: number;\n\n  /**\n   * <p>The delivery stream type. This can be one of the following values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   *          <p>This parameter is optional. If this parameter is omitted, delivery streams of all\n   *          types are returned.</p>\n   */\n  DeliveryStreamType?: DeliveryStreamType | string;\n\n  /**\n   * <p>The list of delivery streams returned by this call to\n   *             <code>ListDeliveryStreams</code> will start with the delivery stream whose name comes\n   *          alphabetically immediately after the name you specify in\n   *             <code>ExclusiveStartDeliveryStreamName</code>.</p>\n   */\n  ExclusiveStartDeliveryStreamName?: string;\n}\n\nexport namespace ListDeliveryStreamsInput {\n  export const filterSensitiveLog = (obj: ListDeliveryStreamsInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface ListDeliveryStreamsOutput {\n  /**\n   * <p>The names of the delivery streams.</p>\n   */\n  DeliveryStreamNames: string[] | undefined;\n\n  /**\n   * <p>Indicates whether there are more delivery streams available to list.</p>\n   */\n  HasMoreDeliveryStreams: boolean | undefined;\n}\n\nexport namespace ListDeliveryStreamsOutput {\n  export const filterSensitiveLog = (obj: ListDeliveryStreamsOutput): any => ({\n    ...obj,\n  });\n}\n\nexport interface ListTagsForDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream whose tags you want to list.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The key to use as the starting point for the list of tags. If you set this parameter,\n   *             <code>ListTagsForDeliveryStream</code> gets all tags that occur after\n   *             <code>ExclusiveStartTagKey</code>.</p>\n   */\n  ExclusiveStartTagKey?: string;\n\n  /**\n   * <p>The number of tags to return. If this number is less than the total number of tags\n   *          associated with the delivery stream, <code>HasMoreTags</code> is set to <code>true</code>\n   *          in the response. To list additional tags, set <code>ExclusiveStartTagKey</code> to the last\n   *          key in the response. </p>\n   */\n  Limit?: number;\n}\n\nexport namespace ListTagsForDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: ListTagsForDeliveryStreamInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface ListTagsForDeliveryStreamOutput {\n  /**\n   * <p>A list of tags associated with <code>DeliveryStreamName</code>, starting with the\n   *          first tag after <code>ExclusiveStartTagKey</code> and up to the specified\n   *             <code>Limit</code>.</p>\n   */\n  Tags: Tag[] | undefined;\n\n  /**\n   * <p>If this is <code>true</code> in the response, more tags are available. To list the\n   *          remaining tags, set <code>ExclusiveStartTagKey</code> to the key of the last tag returned\n   *          and call <code>ListTagsForDeliveryStream</code> again.</p>\n   */\n  HasMoreTags: boolean | undefined;\n}\n\nexport namespace ListTagsForDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: ListTagsForDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The unit of data in a delivery stream.</p>\n */\nexport interface _Record {\n  /**\n   * <p>The data blob, which is base64-encoded when the blob is serialized. The maximum size\n   *          of the data blob, before base64-encoding, is 1,000 KiB.</p>\n   */\n  Data: Uint8Array | undefined;\n}\n\nexport namespace _Record {\n  export const filterSensitiveLog = (obj: _Record): any => ({\n    ...obj,\n  });\n}\n\nexport interface PutRecordInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The record.</p>\n   */\n  Record: _Record | undefined;\n}\n\nexport namespace PutRecordInput {\n  export const filterSensitiveLog = (obj: PutRecordInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface PutRecordOutput {\n  /**\n   * <p>The ID of the record.</p>\n   */\n  RecordId: string | undefined;\n\n  /**\n   * <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>\n   */\n  Encrypted?: boolean;\n}\n\nexport namespace PutRecordOutput {\n  export const filterSensitiveLog = (obj: PutRecordOutput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>The service is unavailable. Back off and retry the operation. If you continue to see\n *          the exception, throughput limits for the delivery stream may have been exceeded. For more\n *          information about limits and how to request an increase, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/limits.html\">Amazon Kinesis Data Firehose\n *          Limits</a>.</p>\n */\nexport interface ServiceUnavailableException extends __SmithyException, $MetadataBearer {\n  name: \"ServiceUnavailableException\";\n  $fault: \"server\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ServiceUnavailableException {\n  export const filterSensitiveLog = (obj: ServiceUnavailableException): any => ({\n    ...obj,\n  });\n}\n\nexport interface PutRecordBatchInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>One or more records.</p>\n   */\n  Records: _Record[] | undefined;\n}\n\nexport namespace PutRecordBatchInput {\n  export const filterSensitiveLog = (obj: PutRecordBatchInput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Contains the result for an individual record from a <a>PutRecordBatch</a>\n *          request. If the record is successfully added to your delivery stream, it receives a record\n *          ID. If the record fails to be added to your delivery stream, the result includes an error\n *          code and an error message.</p>\n */\nexport interface PutRecordBatchResponseEntry {\n  /**\n   * <p>The ID of the record.</p>\n   */\n  RecordId?: string;\n\n  /**\n   * <p>The error code for an individual record result.</p>\n   */\n  ErrorCode?: string;\n\n  /**\n   * <p>The error message for an individual record result.</p>\n   */\n  ErrorMessage?: string;\n}\n\nexport namespace PutRecordBatchResponseEntry {\n  export const filterSensitiveLog = (obj: PutRecordBatchResponseEntry): any => ({\n    ...obj,\n  });\n}\n\nexport interface PutRecordBatchOutput {\n  /**\n   * <p>The number of records that might have failed processing. This number might be greater\n   *          than 0 even if the <a>PutRecordBatch</a> call succeeds. Check\n   *             <code>FailedPutCount</code> to determine whether there are records that you need to\n   *          resend.</p>\n   */\n  FailedPutCount: number | undefined;\n\n  /**\n   * <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>\n   */\n  Encrypted?: boolean;\n\n  /**\n   * <p>The results array. For each record, the index of the response element is the same as\n   *          the index used in the request array.</p>\n   */\n  RequestResponses: PutRecordBatchResponseEntry[] | undefined;\n}\n\nexport namespace PutRecordBatchOutput {\n  export const filterSensitiveLog = (obj: PutRecordBatchOutput): any => ({\n    ...obj,\n  });\n}\n\nexport interface StartDeliveryStreamEncryptionInput {\n  /**\n   * <p>The name of the delivery stream for which you want to enable server-side encryption\n   *          (SSE).</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for\n   *          Server-Side Encryption (SSE).</p>\n   */\n  DeliveryStreamEncryptionConfigurationInput?: DeliveryStreamEncryptionConfigurationInput;\n}\n\nexport namespace StartDeliveryStreamEncryptionInput {\n  export const filterSensitiveLog = (obj: StartDeliveryStreamEncryptionInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface StartDeliveryStreamEncryptionOutput {}\n\nexport namespace StartDeliveryStreamEncryptionOutput {\n  export const filterSensitiveLog = (obj: StartDeliveryStreamEncryptionOutput): any => ({\n    ...obj,\n  });\n}\n\nexport interface StopDeliveryStreamEncryptionInput {\n  /**\n   * <p>The name of the delivery stream for which you want to disable server-side encryption\n   *          (SSE).</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace StopDeliveryStreamEncryptionInput {\n  export const filterSensitiveLog = (obj: StopDeliveryStreamEncryptionInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface StopDeliveryStreamEncryptionOutput {}\n\nexport namespace StopDeliveryStreamEncryptionOutput {\n  export const filterSensitiveLog = (obj: StopDeliveryStreamEncryptionOutput): any => ({\n    ...obj,\n  });\n}\n\nexport interface TagDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream to which you want to add the tags.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>A set of key-value pairs to use to create the tags.</p>\n   */\n  Tags: Tag[] | undefined;\n}\n\nexport namespace TagDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: TagDeliveryStreamInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface TagDeliveryStreamOutput {}\n\nexport namespace TagDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: TagDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n}\n\nexport interface UntagDeliveryStreamInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>A list of tag keys. Each corresponding tag is removed from the delivery\n   *          stream.</p>\n   */\n  TagKeys: string[] | undefined;\n}\n\nexport namespace UntagDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: UntagDeliveryStreamInput): any => ({\n    ...obj,\n  });\n}\n\nexport interface UntagDeliveryStreamOutput {}\n\nexport namespace UntagDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: UntagDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n}\n\n/**\n * <p>Updates the specified HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationUpdate {\n  /**\n   * <p>Describes the configuration of the HTTP endpoint destination.</p>\n   */\n  EndpointConfiguration?: HttpEndpointConfiguration;\n\n  /**\n   * <p>Describes buffering options that can be applied to the data before it is delivered to\n   *          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it\n   *          might choose to use more optimal values. The <code>SizeInMBs</code> and\n   *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n   *          one of them, you must also provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The configuration of the request sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to\n   *          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only\n   *          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint\n   *          destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes an update for a destination in Amazon S3.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n}\n\nexport namespace HttpEndpointDestinationUpdate {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationUpdate): any => ({\n    ...obj,\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n  });\n}\n\n/**\n * <p>Describes an update for a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationUpdate {\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL?: string;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand?: CopyCommand;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username?: string;\n\n  /**\n   * <p>The user password.</p>\n   */\n  Password?: string;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          in <code>RedshiftDestinationUpdate.S3Update</code> because the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket doesn't support these\n   *          compression formats.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If\n   *          backup is enabled, you can't update the delivery stream to disable it. </p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n\n  /**\n   * <p>The Amazon S3 destination for backup.</p>\n   */\n  S3BackupUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace RedshiftDestinationUpdate {\n  export const filterSensitiveLog = (obj: RedshiftDestinationUpdate): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n    ...(obj.Password && { Password: SENSITIVE_STRING }),\n  });\n}\n\n/**\n * <p>Describes an update for a destination in Splunk.</p>\n */\nexport interface SplunkDestinationUpdate {\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint?: string;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType?: HECEndpointType | string;\n\n  /**\n   * <p>A GUID that you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken?: string;\n\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends data. At the end of the timeout period, Kinesis Data Firehose either\n   *          tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>Specifies how you want Kinesis Data Firehose to back up documents to Amazon S3. When\n   *          set to <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could\n   *          not be indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>\n   *          <p>You can update this backup mode from <code>FailedEventsOnly</code> to\n   *             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to\n   *             <code>FailedEventsOnly</code>.</p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n\n  /**\n   * <p>Your update to the configuration of the backup Amazon S3 location.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n}\n\nexport namespace SplunkDestinationUpdate {\n  export const filterSensitiveLog = (obj: SplunkDestinationUpdate): any => ({\n    ...obj,\n  });\n}\n\nexport interface UpdateDestinationInput {\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Obtain this value from the <code>VersionId</code> result of <a>DeliveryStreamDescription</a>. This value is required, and helps the service\n   *          perform conditional operations. For example, if there is an interleaving update and this\n   *          value is null, then the update destination fails. After the update is successful, the\n   *             <code>VersionId</code> value is updated. The service then performs a merge of the old\n   *          configuration with the new configuration.</p>\n   */\n  CurrentDeliveryStreamVersionId: string | undefined;\n\n  /**\n   * <p>The ID of the destination.</p>\n   */\n  DestinationId: string | undefined;\n\n  /**\n   * @deprecated\n   *\n   * <p>[Deprecated] Describes an update for a destination in Amazon S3.</p>\n   */\n  S3DestinationUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Amazon S3.</p>\n   */\n  ExtendedS3DestinationUpdate?: ExtendedS3DestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Amazon Redshift.</p>\n   */\n  RedshiftDestinationUpdate?: RedshiftDestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Amazon ES.</p>\n   */\n  ElasticsearchDestinationUpdate?: ElasticsearchDestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Splunk.</p>\n   */\n  SplunkDestinationUpdate?: SplunkDestinationUpdate;\n\n  /**\n   * <p>Describes an update to the specified HTTP endpoint destination.</p>\n   */\n  HttpEndpointDestinationUpdate?: HttpEndpointDestinationUpdate;\n}\n\nexport namespace UpdateDestinationInput {\n  export const filterSensitiveLog = (obj: UpdateDestinationInput): any => ({\n    ...obj,\n    ...(obj.RedshiftDestinationUpdate && {\n      RedshiftDestinationUpdate: RedshiftDestinationUpdate.filterSensitiveLog(obj.RedshiftDestinationUpdate),\n    }),\n    ...(obj.HttpEndpointDestinationUpdate && {\n      HttpEndpointDestinationUpdate: HttpEndpointDestinationUpdate.filterSensitiveLog(\n        obj.HttpEndpointDestinationUpdate\n      ),\n    }),\n  });\n}\n\nexport interface UpdateDestinationOutput {}\n\nexport namespace UpdateDestinationOutput {\n  export const filterSensitiveLog = (obj: UpdateDestinationOutput): any => ({\n    ...obj,\n  });\n}\n"],"mappings":";AAAA,SAASA,gBAAgB,QAA8C,wBAAwB;AA+B/F,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAAC,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;AACJ,CAAC,EAJgBF,cAAc,KAAdA,cAAc;AA4B/B,OAAM,IAAWI,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAH,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgBE,wBAAwB,KAAxBA,wBAAwB;AAMzC,WAAYC,iBAMX;AAND,WAAYA,iBAAiB;EAC3BA,iBAAA,iBAAa;EACbA,iBAAA,mCAA+B;EAC/BA,iBAAA,qBAAiB;EACjBA,iBAAA,iCAA6B;EAC7BA,iBAAA,eAAW;AACb,CAAC,EANWA,iBAAiB,KAAjBA,iBAAiB;AAqB7B,OAAM,IAAWC,+BAA+B;AAAhD,WAAiBA,+BAA+B;EACjCA,+BAAA,CAAAL,kBAAkB,GAAG,UAACC,GAAoC;IAAU,OAAAC,QAAA,KAC5ED,GAAG;EADyE,CAE/E;AACJ,CAAC,EAJgBI,+BAA+B,KAA/BA,+BAA+B;AAMhD,WAAYC,eAGX;AAHD,WAAYA,eAAe;EACzBA,eAAA,iBAAa;EACbA,eAAA,iBAAa;AACf,CAAC,EAHWA,eAAe,KAAfA,eAAe;AA4C3B,OAAM,IAAWC,WAAW;AAA5B,WAAiBA,WAAW;EACbA,WAAA,CAAAP,kBAAkB,GAAG,UAACC,GAAgB;IAAU,OAAAC,QAAA,KACxDD,GAAG;EADqD,CAE3D;AACJ,CAAC,EAJgBM,WAAW,KAAXA,WAAW;AAM5B,WAAYC,OAGX;AAHD,WAAYA,OAAO;EACjBA,OAAA,mCAA+B;EAC/BA,OAAA,iDAA6C;AAC/C,CAAC,EAHWA,OAAO,KAAPA,OAAO;AAwCnB,OAAM,IAAWC,0CAA0C;AAA3D,WAAiBA,0CAA0C;EAC5CA,0CAAA,CAAAT,kBAAkB,GAAG,UAACC,GAA+C;IAAU,OAAAC,QAAA,KACvFD,GAAG;EADoF,CAE1F;AACJ,CAAC,EAJgBQ,0CAA0C,KAA1CA,0CAA0C;AA6B3D,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAV,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgBS,2BAA2B,KAA3BA,2BAA2B;AAQ5C,WAAYC,sBAMX;AAND,WAAYA,sBAAsB;EAChCA,sBAAA,0DAAsD;EACtDA,sBAAA,yCAAqC;EACrCA,sBAAA,4BAAwB;EACxBA,sBAAA,gDAA4C;EAC5CA,sBAAA,wBAAoB;AACtB,CAAC,EANWA,sBAAsB,KAAtBA,sBAAsB;AAuBlC,OAAM,IAAWC,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAAZ,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;AACJ,CAAC,EAJgBW,kBAAkB,KAAlBA,kBAAkB;AAuBnC,OAAM,IAAWC,SAAS;AAA1B,WAAiBA,SAAS;EACXA,SAAA,CAAAb,kBAAkB,GAAG,UAACC,GAAc;IAAU,OAAAC,QAAA,KACtDD,GAAG;EADmD,CAEzD;AACJ,CAAC,EAJgBY,SAAS,KAATA,SAAS;AAqB1B,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAd,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;AACJ,CAAC,EAJgBa,uBAAuB,KAAvBA,uBAAuB;AAoBxC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAf,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgBc,yBAAyB,KAAzBA,yBAAyB;AAoB1C,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAAhB,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;AACJ,CAAC,EAJgBe,mBAAmB,KAAnBA,mBAAmB;AAwBpC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAjB,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;AACJ,CAAC,EAJgBgB,uBAAuB,KAAvBA,uBAAuB;AAgExC,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAAlB,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;AACJ,CAAC,EAJgBiB,0BAA0B,KAA1BA,0BAA0B;AA4F3C,OAAM,IAAWC,gBAAgB;AAAjC,WAAiBA,gBAAgB;EAClBA,gBAAA,CAAAnB,kBAAkB,GAAG,UAACC,GAAqB;IAAU,OAAAC,QAAA,KAC7DD,GAAG;EAD0D,CAEhE;AACJ,CAAC,EAJgBkB,gBAAgB,KAAhBA,gBAAgB;AAyGjC,OAAM,IAAWC,qCAAqC;AAAtD,WAAiBA,qCAAqC;EACvCA,qCAAA,CAAApB,kBAAkB,GAAG,UAACC,GAA0C;IAAU,OAAAC,QAAA,KAClFD,GAAG;EAD+E,CAErF;AACJ,CAAC,EAJgBmB,qCAAqC,KAArCA,qCAAqC;AAuBtD,OAAM,IAAWC,aAAa;AAA9B,WAAiBA,aAAa;EACfA,aAAA,CAAArB,kBAAkB,GAAG,UAACC,GAAkB;IAAU,OAAAC,QAAA,KAC1DD,GAAG;EADuD,CAE7D;AACJ,CAAC,EAJgBoB,aAAa,KAAbA,aAAa;AAuC9B,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAAtB,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;AACJ,CAAC,EAJgBqB,cAAc,KAAdA,cAAc;AA8B/B,OAAM,IAAWC,YAAY;AAA7B,WAAiBA,YAAY;EACdA,YAAA,CAAAvB,kBAAkB,GAAG,UAACC,GAAiB;IAAU,OAAAC,QAAA,KACzDD,GAAG;EADsD,CAE5D;AACJ,CAAC,EAJgBsB,YAAY,KAAZA,YAAY;AAkB7B,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAxB,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgBuB,wBAAwB,KAAxBA,wBAAwB;AAMzC,WAAYC,cAIX;AAJD,WAAYA,cAAc;EACxBA,cAAA,iBAAa;EACbA,cAAA,qBAAiB;EACjBA,cAAA,iBAAa;AACf,CAAC,EAJWA,cAAc,KAAdA,cAAc;AAM1B,WAAYC,gBAGX;AAHD,WAAYA,gBAAgB;EAC1BA,gBAAA,mBAAe;EACfA,gBAAA,mBAAe;AACjB,CAAC,EAHWA,gBAAgB,KAAhBA,gBAAgB;AAiF5B,OAAM,IAAWC,QAAQ;AAAzB,WAAiBA,QAAQ;EACVA,QAAA,CAAA3B,kBAAkB,GAAG,UAACC,GAAa;IAAU,OAAAC,QAAA,KACrDD,GAAG;EADkD,CAExD;AACJ,CAAC,EAJgB0B,QAAQ,KAARA,QAAQ;AAMzB,WAAYC,kBAIX;AAJD,WAAYA,kBAAkB;EAC5BA,kBAAA,iBAAa;EACbA,kBAAA,qBAAiB;EACjBA,kBAAA,iCAA6B;AAC/B,CAAC,EAJWA,kBAAkB,KAAlBA,kBAAkB;AAM9B,WAAYC,oBAGX;AAHD,WAAYA,oBAAoB;EAC9BA,oBAAA,aAAS;EACTA,oBAAA,aAAS;AACX,CAAC,EAHWA,oBAAoB,KAApBA,oBAAoB;AAkDhC,OAAM,IAAWC,YAAY;AAA7B,WAAiBA,YAAY;EACdA,YAAA,CAAA9B,kBAAkB,GAAG,UAACC,GAAiB;IAAU,OAAAC,QAAA,KACzDD,GAAG;EADsD,CAE5D;AACJ,CAAC,EAJgB6B,YAAY,KAAZA,YAAY;AA0B7B,OAAM,IAAWC,UAAU;AAA3B,WAAiBA,UAAU;EACZA,UAAA,CAAA/B,kBAAkB,GAAG,UAACC,GAAe;IAAU,OAAAC,QAAA,KACvDD,GAAG;EADoD,CAE1D;AACJ,CAAC,EAJgB8B,UAAU,KAAVA,UAAU;AAmB3B,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAhC,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgB+B,yBAAyB,KAAzBA,yBAAyB;AAmD1C,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAAjC,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;AACJ,CAAC,EAJgBgC,mBAAmB,KAAnBA,mBAAmB;AAyCpC,OAAM,IAAWC,iCAAiC;AAAlD,WAAiBA,iCAAiC;EACnCA,iCAAA,CAAAlC,kBAAkB,GAAG,UAACC,GAAsC;IAAU,OAAAC,QAAA,KAC9ED,GAAG;EAD2E,CAEjF;AACJ,CAAC,EAJgBiC,iCAAiC,KAAjCA,iCAAiC;AAqFlD,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAAnC,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;AACJ,CAAC,EAJgBkC,kCAAkC,KAAlCA,kCAAkC;AA8BnD,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAApC,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;AACJ,CAAC,EAJgBmC,0BAA0B,KAA1BA,0BAA0B;AA4B3C,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAArC,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACqC,GAAG,IAAI;MAAEA,GAAG,EAAExC;IAAgB,CAAG,GACrCG,GAAG,CAACsC,SAAS,IAAI;MAAEA,SAAS,EAAEzC;IAAgB,CAAG;EAHoB,CAIzE;AACJ,CAAC,EANgBuC,yBAAyB,KAAzBA,yBAAyB;AAwB1C,OAAM,IAAWG,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAxC,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACxED,GAAG,GACFA,GAAG,CAACwC,aAAa,IAAI;MAAEA,aAAa,EAAE3C;IAAgB,CAAG,GACzDG,GAAG,CAACyC,cAAc,IAAI;MAAEA,cAAc,EAAE5C;IAAgB,CAAG;EAHY,CAI3E;AACJ,CAAC,EANgB0C,2BAA2B,KAA3BA,2BAA2B;AAwB5C,OAAM,IAAWG,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAA3C,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KAC7ED,GAAG,GACFA,GAAG,CAAC2C,gBAAgB,IAAI;MAC1BA,gBAAgB,EAAE3C,GAAG,CAAC2C,gBAAgB,CAACC,GAAG,CAAC,UAACC,IAAI;QAAK,OAAAN,2BAA2B,CAACxC,kBAAkB,CAAC8C,IAAI,CAAC;MAApD,CAAoD;KACzG;EAJ8E,CAKhF;AACJ,CAAC,EAPgBH,gCAAgC,KAAhCA,gCAAgC;AAwBjD,OAAM,IAAWI,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA/C,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgB8C,wBAAwB,KAAxBA,wBAAwB;AAqEzC,OAAM,IAAWC,oCAAoC;AAArD,WAAiBA,oCAAoC;EACtCA,oCAAA,CAAAhD,kBAAkB,GAAG,UAACC,GAAyC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACjFD,GAAG,GACFA,GAAG,CAACgD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAEZ,yBAAyB,CAACrC,kBAAkB,CAACC,GAAG,CAACgD,qBAAqB;KAC7F,GACEhD,GAAG,CAACiD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEP,gCAAgC,CAAC3C,kBAAkB,CAACC,GAAG,CAACiD,oBAAoB;KAClG;EAPkF,CAQpF;AACJ,CAAC,EAVgBF,oCAAoC,KAApCA,oCAAoC;AA6BrD,OAAM,IAAWG,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAAnD,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,KAC7ED,GAAG;EAD0E,CAEhF;AACJ,CAAC,EAJgBkD,gCAAgC,KAAhCA,gCAAgC;AAqBjD,OAAM,IAAWC,oBAAoB;AAArC,WAAiBA,oBAAoB;EACtBA,oBAAA,CAAApD,kBAAkB,GAAG,UAACC,GAAyB;IAAU,OAAAC,QAAA,KACjED,GAAG;EAD8D,CAEpE;AACJ,CAAC,EAJgBmD,oBAAoB,KAApBA,oBAAoB;AA6ErC,OAAM,IAAWC,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAArD,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC7ED,GAAG,GACFA,GAAG,CAACqD,QAAQ,IAAI;MAAEA,QAAQ,EAAExD;IAAgB,CAAG,GAC/CG,GAAG,CAACsD,QAAQ,IAAI;MAAEA,QAAQ,EAAEzD;IAAgB,CAAG;EAH6B,CAIhF;AACJ,CAAC,EANgBuD,gCAAgC,KAAhCA,gCAAgC;AAwBjD,OAAM,IAAWG,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAAxD,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;AACJ,CAAC,EAJgBuD,kBAAkB,KAAlBA,kBAAkB;AAuEnC,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAzD,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;AACJ,CAAC,EAJgBwD,8BAA8B,KAA9BA,8BAA8B;AAyB/C,OAAM,IAAWC,GAAG;AAApB,WAAiBA,GAAG;EACLA,GAAA,CAAA1D,kBAAkB,GAAG,UAACC,GAAQ;IAAU,OAAAC,QAAA,KAChDD,GAAG;EAD6C,CAEnD;AACJ,CAAC,EAJgByD,GAAG,KAAHA,GAAG;AA0FpB,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA3D,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACoD,gCAAgC,IAAI;MAC1CA,gCAAgC,EAAEA,gCAAgC,CAACrD,kBAAkB,CACnFC,GAAG,CAACoD,gCAAgC;KAEtC,GACEpD,GAAG,CAAC+C,oCAAoC,IAAI;MAC9CA,oCAAoC,EAAEA,oCAAoC,CAAChD,kBAAkB,CAC3FC,GAAG,CAAC+C,oCAAoC;KAE1C;EAXuE,CAYzE;AACJ,CAAC,EAdgBW,yBAAyB,KAAzBA,yBAAyB;AAuB1C,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAA5D,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;AACJ,CAAC,EAJgB2D,0BAA0B,KAA1BA,0BAA0B;AAkB3C,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA7D,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgB4D,wBAAwB,KAAxBA,wBAAwB;AAoBzC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA9D,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgB6D,2BAA2B,KAA3BA,2BAA2B;AAkB5C,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAA/D,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;AACJ,CAAC,EAJgB8D,sBAAsB,KAAtBA,sBAAsB;AAkBvC,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAAhE,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;AACJ,CAAC,EAJgB+D,sBAAsB,KAAtBA,sBAAsB;AAwBvC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAjE,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgBgE,yBAAyB,KAAzBA,yBAAyB;AAQ1C,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAAlE,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;AACJ,CAAC,EAJgBiE,0BAA0B,KAA1BA,0BAA0B;AAkB3C,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAnE,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgBkE,yBAAyB,KAAzBA,yBAAyB;AAM1C,WAAYC,yBAgBX;AAhBD,WAAYA,yBAAyB;EACnCA,yBAAA,2CAAuC;EACvCA,yBAAA,uDAAmD;EACnDA,yBAAA,2CAAuC;EACvCA,yBAAA,yCAAqC;EACrCA,yBAAA,2CAAuC;EACvCA,yBAAA,uCAAmC;EACnCA,yBAAA,2CAAuC;EACvCA,yBAAA,2CAAuC;EACvCA,yBAAA,+CAA2C;EAC3CA,yBAAA,uDAAmD;EACnDA,yBAAA,iEAA6D;EAC7DA,yBAAA,yDAAqD;EACrDA,yBAAA,iDAA6C;EAC7CA,yBAAA,yCAAqC;EACrCA,yBAAA,mCAA+B;AACjC,CAAC,EAhBWA,yBAAyB,KAAzBA,yBAAyB;AAmCrC,OAAM,IAAWC,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAArE,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;AACJ,CAAC,EAJgBoE,kBAAkB,KAAlBA,kBAAkB;AAMnC,WAAYC,8BAOX;AAPD,WAAYA,8BAA8B;EACxCA,8BAAA,yBAAqB;EACrBA,8BAAA,2BAAuB;EACvBA,8BAAA,yCAAqC;EACrCA,8BAAA,uBAAmB;EACnBA,8BAAA,yBAAqB;EACrBA,8BAAA,uCAAmC;AACrC,CAAC,EAPWA,8BAA8B,KAA9BA,8BAA8B;AA6C1C,OAAM,IAAWC,qCAAqC;AAAtD,WAAiBA,qCAAqC;EACvCA,qCAAA,CAAAvE,kBAAkB,GAAG,UAACC,GAA0C;IAAU,OAAAC,QAAA,KAClFD,GAAG;EAD+E,CAErF;AACJ,CAAC,EAJgBsE,qCAAqC,KAArCA,qCAAqC;AAMtD,WAAYC,oBAMX;AAND,WAAYA,oBAAoB;EAC9BA,oBAAA,qBAAiB;EACjBA,oBAAA,yBAAqB;EACrBA,oBAAA,uCAAmC;EACnCA,oBAAA,yBAAqB;EACrBA,oBAAA,uCAAmC;AACrC,CAAC,EANWA,oBAAoB,KAApBA,oBAAoB;AA+DhC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAzE,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgBwE,wBAAwB,KAAxBA,wBAAwB;AAgGzC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA1E,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgByE,2BAA2B,KAA3BA,2BAA2B;AAoF5C,OAAM,IAAWC,mCAAmC;AAApD,WAAiBA,mCAAmC;EACrCA,mCAAA,CAAA3E,kBAAkB,GAAG,UAACC,GAAwC;IAAU,OAAAC,QAAA,KAChFD,GAAG;EAD6E,CAEnF;AACJ,CAAC,EAJgB0E,mCAAmC,KAAnCA,mCAAmC;AAiFpD,OAAM,IAAWC,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAA5E,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,KAC7ED,GAAG;EAD0E,CAEhF;AACJ,CAAC,EAJgB2E,gCAAgC,KAAhCA,gCAAgC;AAqBjD,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAA7E,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACpED,GAAG,GACFA,GAAG,CAACqC,GAAG,IAAI;MAAEA,GAAG,EAAExC;IAAgB,CAAG;EAF8B,CAGvE;AACJ,CAAC,EALgB+E,uBAAuB,KAAvBA,uBAAuB;AAoExC,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAA9E,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC/ED,GAAG,GACFA,GAAG,CAACgD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAE4B,uBAAuB,CAAC7E,kBAAkB,CAACC,GAAG,CAACgD,qBAAqB;KAC3F,GACEhD,GAAG,CAACiD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEP,gCAAgC,CAAC3C,kBAAkB,CAACC,GAAG,CAACiD,oBAAoB;KAClG;EAPgF,CAQlF;AACJ,CAAC,EAVgB4B,kCAAkC,KAAlCA,kCAAkC;AAqEnD,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAA/E,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KAC3ED,GAAG,GACFA,GAAG,CAACqD,QAAQ,IAAI;MAAEA,QAAQ,EAAExD;IAAgB,CAAG;EAF2B,CAG9E;AACJ,CAAC,EALgBiF,8BAA8B,KAA9BA,8BAA8B;AAmE/C,OAAM,IAAWC,4BAA4B;AAA7C,WAAiBA,4BAA4B;EAC9BA,4BAAA,CAAAhF,kBAAkB,GAAG,UAACC,GAAiC;IAAU,OAAAC,QAAA,KACzED,GAAG;EADsE,CAE5E;AACJ,CAAC,EAJgB+E,4BAA4B,KAA5BA,4BAA4B;AA8C7C,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAAjF,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACnED,GAAG,GACFA,GAAG,CAAC8E,8BAA8B,IAAI;MACxCA,8BAA8B,EAAEA,8BAA8B,CAAC/E,kBAAkB,CAC/EC,GAAG,CAAC8E,8BAA8B;KAEpC,GACE9E,GAAG,CAAC6E,kCAAkC,IAAI;MAC5CA,kCAAkC,EAAEA,kCAAkC,CAAC9E,kBAAkB,CACvFC,GAAG,CAAC6E,kCAAkC;KAExC;EAXoE,CAYtE;AACJ,CAAC,EAdgBG,sBAAsB,KAAtBA,sBAAsB;AAwCvC,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAlF,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;AACJ,CAAC,EAJgBiF,8BAA8B,KAA9BA,8BAA8B;AAkB/C,OAAM,IAAWC,iBAAiB;AAAlC,WAAiBA,iBAAiB;EACnBA,iBAAA,CAAAnF,kBAAkB,GAAG,UAACC,GAAsB;IAAU,OAAAC,QAAA,KAC9DD,GAAG;EAD2D,CAEjE;AACJ,CAAC,EAJgBkF,iBAAiB,KAAjBA,iBAAiB;AA6FlC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAApF,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACoF,YAAY,IAAI;MACtBA,YAAY,EAAEpF,GAAG,CAACoF,YAAY,CAACxC,GAAG,CAAC,UAACC,IAAI;QAAK,OAAAmC,sBAAsB,CAACjF,kBAAkB,CAAC8C,IAAI,CAAC;MAA/C,CAA+C;KAC5F;EAJuE,CAKzE;AACJ,CAAC,EAPgBsC,yBAAyB,KAAzBA,yBAAyB;AA4B1C,OAAM,IAAWE,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAtF,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgBqF,2BAA2B,KAA3BA,2BAA2B;AAa5C,OAAM,IAAWC,4BAA4B;AAA7C,WAAiBA,4BAA4B;EAC9BA,4BAAA,CAAAvF,kBAAkB,GAAG,UAACC,GAAiC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACzED,GAAG,GACFA,GAAG,CAACmF,yBAAyB,IAAI;MACnCA,yBAAyB,EAAEA,yBAAyB,CAACpF,kBAAkB,CAACC,GAAG,CAACmF,yBAAyB;KACrG;EAJ0E,CAK5E;AACJ,CAAC,EAPgBG,4BAA4B,KAA5BA,4BAA4B;AAmE7C,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAAxF,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;AACJ,CAAC,EAJgBuF,mBAAmB,KAAnBA,mBAAmB;AAyFpC,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAzF,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;AACJ,CAAC,EAJgBwF,8BAA8B,KAA9BA,8BAA8B;AAkF/C,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA1F,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgByF,2BAA2B,KAA3BA,2BAA2B;AAwC5C,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA3F,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgB0F,wBAAwB,KAAxBA,wBAAwB;AAkBzC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA5F,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgB2F,yBAAyB,KAAzBA,yBAAyB;AA4B1C,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAA7F,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;AACJ,CAAC,EAJgB4F,8BAA8B,KAA9BA,8BAA8B;AAsB/C,OAAM,IAAWC,+BAA+B;AAAhD,WAAiBA,+BAA+B;EACjCA,+BAAA,CAAA9F,kBAAkB,GAAG,UAACC,GAAoC;IAAU,OAAAC,QAAA,KAC5ED,GAAG;EADyE,CAE/E;AACJ,CAAC,EAJgB6F,+BAA+B,KAA/BA,+BAA+B;AAiBhD,OAAM,IAAWC,OAAO;AAAxB,WAAiBA,OAAO;EACTA,OAAA,CAAA/F,kBAAkB,GAAG,UAACC,GAAY;IAAU,OAAAC,QAAA,KACpDD,GAAG;EADiD,CAEvD;AACJ,CAAC,EAJgB8F,OAAO,KAAPA,OAAO;AAkBxB,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAAhG,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;AACJ,CAAC,EAJgB+F,cAAc,KAAdA,cAAc;AAkB/B,OAAM,IAAWC,eAAe;AAAhC,WAAiBA,eAAe;EACjBA,eAAA,CAAAjG,kBAAkB,GAAG,UAACC,GAAoB;IAAU,OAAAC,QAAA,KAC5DD,GAAG;EADyD,CAE/D;AACJ,CAAC,EAJgBgG,eAAe,KAAfA,eAAe;AAqBhC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAlG,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgBiG,2BAA2B,KAA3BA,2BAA2B;AAkB5C,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAAnG,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;AACJ,CAAC,EAJgBkG,mBAAmB,KAAnBA,mBAAmB;AA6BpC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAApG,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;AACJ,CAAC,EAJgBmG,2BAA2B,KAA3BA,2BAA2B;AA2B5C,OAAM,IAAWC,oBAAoB;AAArC,WAAiBA,oBAAoB;EACtBA,oBAAA,CAAArG,kBAAkB,GAAG,UAACC,GAAyB;IAAU,OAAAC,QAAA,KACjED,GAAG;EAD8D,CAEpE;AACJ,CAAC,EAJgBoG,oBAAoB,KAApBA,oBAAoB;AAoBrC,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAAtG,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;AACJ,CAAC,EAJgBqG,kCAAkC,KAAlCA,kCAAkC;AAQnD,OAAM,IAAWC,mCAAmC;AAApD,WAAiBA,mCAAmC;EACrCA,mCAAA,CAAAvG,kBAAkB,GAAG,UAACC,GAAwC;IAAU,OAAAC,QAAA,KAChFD,GAAG;EAD6E,CAEnF;AACJ,CAAC,EAJgBsG,mCAAmC,KAAnCA,mCAAmC;AAcpD,OAAM,IAAWC,iCAAiC;AAAlD,WAAiBA,iCAAiC;EACnCA,iCAAA,CAAAxG,kBAAkB,GAAG,UAACC,GAAsC;IAAU,OAAAC,QAAA,KAC9ED,GAAG;EAD2E,CAEjF;AACJ,CAAC,EAJgBuG,iCAAiC,KAAjCA,iCAAiC;AAQlD,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAAzG,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;AACJ,CAAC,EAJgBwG,kCAAkC,KAAlCA,kCAAkC;AAkBnD,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAA1G,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;AACJ,CAAC,EAJgByG,sBAAsB,KAAtBA,sBAAsB;AAQvC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAA3G,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;AACJ,CAAC,EAJgB0G,uBAAuB,KAAvBA,uBAAuB;AAmBxC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA5G,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;AACJ,CAAC,EAJgB2G,wBAAwB,KAAxBA,wBAAwB;AAQzC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA7G,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;AACJ,CAAC,EAJgB4G,yBAAyB,KAAzBA,yBAAyB;AAmE1C,OAAM,IAAWC,6BAA6B;AAA9C,WAAiBA,6BAA6B;EAC/BA,6BAAA,CAAA9G,kBAAkB,GAAG,UAACC,GAAkC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC1ED,GAAG,GACFA,GAAG,CAACgD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAEZ,yBAAyB,CAACrC,kBAAkB,CAACC,GAAG,CAACgD,qBAAqB;KAC7F,GACEhD,GAAG,CAACiD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEP,gCAAgC,CAAC3C,kBAAkB,CAACC,GAAG,CAACiD,oBAAoB;KAClG;EAP2E,CAQ7E;AACJ,CAAC,EAVgB4D,6BAA6B,KAA7BA,6BAA6B;AA+E9C,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA/G,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACqD,QAAQ,IAAI;MAAEA,QAAQ,EAAExD;IAAgB,CAAG,GAC/CG,GAAG,CAACsD,QAAQ,IAAI;MAAEA,QAAQ,EAAEzD;IAAgB,CAAG;EAHsB,CAIzE;AACJ,CAAC,EANgBiH,yBAAyB,KAAzBA,yBAAyB;AAuE1C,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAhH,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;AACJ,CAAC,EAJgB+G,uBAAuB,KAAvBA,uBAAuB;AA2DxC,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAAjH,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACnED,GAAG,GACFA,GAAG,CAAC8G,yBAAyB,IAAI;MACnCA,yBAAyB,EAAEA,yBAAyB,CAAC/G,kBAAkB,CAACC,GAAG,CAAC8G,yBAAyB;KACrG,GACE9G,GAAG,CAAC6G,6BAA6B,IAAI;MACvCA,6BAA6B,EAAEA,6BAA6B,CAAC9G,kBAAkB,CAC7EC,GAAG,CAAC6G,6BAA6B;KAEnC;EAToE,CAUtE;AACJ,CAAC,EAZgBG,sBAAsB,KAAtBA,sBAAsB;AAgBvC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAlH,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;AACJ,CAAC,EAJgBiH,uBAAuB,KAAvBA,uBAAuB"},"metadata":{},"sourceType":"module","externalDependencies":[]}