{"ast":null,"code":"import { __extends } from \"tslib\";\nimport { CreateDeliveryStreamInput, CreateDeliveryStreamOutput } from \"../models/models_0\";\nimport { deserializeAws_json1_1CreateDeliveryStreamCommand, serializeAws_json1_1CreateDeliveryStreamCommand } from \"../protocols/Aws_json1_1\";\nimport { getSerdePlugin } from \"@aws-sdk/middleware-serde\";\nimport { Command as $Command } from \"@aws-sdk/smithy-client\";\n/**\n * <p>Creates a Kinesis Data Firehose delivery stream.</p>\n *\n *          <p>By default, you can create up to 50 delivery streams per AWS Region.</p>\n *          <p>This is an asynchronous operation that immediately returns. The initial status of the\n *          delivery stream is <code>CREATING</code>. After the delivery stream is created, its status\n *          is <code>ACTIVE</code> and it now accepts data. If the delivery stream creation fails, the\n *          status transitions to <code>CREATING_FAILED</code>. Attempts to send data to a delivery\n *          stream that is not in the <code>ACTIVE</code> state cause an exception. To check the state\n *          of a delivery stream, use <a>DescribeDeliveryStream</a>.</p>\n *          <p>If the status of a delivery stream is <code>CREATING_FAILED</code>, this status\n *          doesn't change, and you can't invoke <code>CreateDeliveryStream</code> again on it.\n *          However, you can invoke the <a>DeleteDeliveryStream</a> operation to delete\n *          it.</p>\n *          <p>A Kinesis Data Firehose delivery stream can be configured to receive records directly\n *          from providers using <a>PutRecord</a> or <a>PutRecordBatch</a>, or it\n *          can be configured to use an existing Kinesis stream as its source. To specify a Kinesis\n *          data stream as input, set the <code>DeliveryStreamType</code> parameter to\n *             <code>KinesisStreamAsSource</code>, and provide the Kinesis stream Amazon Resource Name\n *          (ARN) and role ARN in the <code>KinesisStreamSourceConfiguration</code>\n *          parameter.</p>\n *          <p>To create a delivery stream with server-side encryption (SSE) enabled, include <a>DeliveryStreamEncryptionConfigurationInput</a> in your request. This is\n *          optional. You can also invoke <a>StartDeliveryStreamEncryption</a> to turn on\n *          SSE for an existing delivery stream that doesn't have SSE enabled.</p>\n *          <p>A delivery stream is configured with a single destination: Amazon S3, Amazon ES,\n *          Amazon Redshift, or Splunk. You must specify only one of the following destination\n *          configuration parameters: <code>ExtendedS3DestinationConfiguration</code>,\n *             <code>S3DestinationConfiguration</code>,\n *             <code>ElasticsearchDestinationConfiguration</code>,\n *             <code>RedshiftDestinationConfiguration</code>, or\n *             <code>SplunkDestinationConfiguration</code>.</p>\n *          <p>When you specify <code>S3DestinationConfiguration</code>, you can also provide the\n *          following optional values: BufferingHints, <code>EncryptionConfiguration</code>, and\n *             <code>CompressionFormat</code>. By default, if no <code>BufferingHints</code> value is\n *          provided, Kinesis Data Firehose buffers data up to 5 MB or for 5 minutes, whichever\n *          condition is satisfied first. <code>BufferingHints</code> is a hint, so there are some\n *          cases where the service cannot adhere to these conditions strictly. For example, record\n *          boundaries might be such that the size is a little over or under the configured buffering\n *          size. By default, no encryption is performed. We strongly recommend that you enable\n *          encryption to ensure secure data storage in Amazon S3.</p>\n *\n *          <p>A few notes about Amazon Redshift as a destination:</p>\n *          <ul>\n *             <li>\n *                <p>An Amazon Redshift destination requires an S3 bucket as intermediate location.\n *                Kinesis Data Firehose first delivers data to Amazon S3 and then uses\n *                   <code>COPY</code> syntax to load data into an Amazon Redshift table. This is\n *                specified in the <code>RedshiftDestinationConfiguration.S3Configuration</code>\n *                parameter.</p>\n *\n *             </li>\n *             <li>\n *                <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be\n *                specified in <code>RedshiftDestinationConfiguration.S3Configuration</code> because\n *                the Amazon Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't\n *                support these compression formats.</p>\n *             </li>\n *             <li>\n *                <p>We strongly recommend that you use the user name and password you provide\n *                exclusively with Kinesis Data Firehose, and that the permissions for the account are\n *                restricted for Amazon Redshift <code>INSERT</code> permissions.</p>\n *\n *             </li>\n *          </ul>\n *          <p>Kinesis Data Firehose assumes the IAM role that is configured as part of the\n *          destination. The role should allow the Kinesis Data Firehose principal to assume the role,\n *          and the role should have permissions that allow the service to deliver the data. For more\n *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n *             Firehose Access to an Amazon S3 Destination</a> in the <i>Amazon Kinesis Data\n *             Firehose Developer Guide</i>.</p>\n */\nvar CreateDeliveryStreamCommand = /** @class */function (_super) {\n  __extends(CreateDeliveryStreamCommand, _super);\n  // Start section: command_properties\n  // End section: command_properties\n  function CreateDeliveryStreamCommand(input) {\n    var _this =\n    // Start section: command_constructor\n    _super.call(this) || this;\n    _this.input = input;\n    return _this;\n    // End section: command_constructor\n  }\n  /**\n   * @internal\n   */\n  CreateDeliveryStreamCommand.prototype.resolveMiddleware = function (clientStack, configuration, options) {\n    this.middlewareStack.use(getSerdePlugin(configuration, this.serialize, this.deserialize));\n    var stack = clientStack.concat(this.middlewareStack);\n    var logger = configuration.logger;\n    var clientName = \"FirehoseClient\";\n    var commandName = \"CreateDeliveryStreamCommand\";\n    var handlerExecutionContext = {\n      logger: logger,\n      clientName: clientName,\n      commandName: commandName,\n      inputFilterSensitiveLog: CreateDeliveryStreamInput.filterSensitiveLog,\n      outputFilterSensitiveLog: CreateDeliveryStreamOutput.filterSensitiveLog\n    };\n    var requestHandler = configuration.requestHandler;\n    return stack.resolve(function (request) {\n      return requestHandler.handle(request.request, options || {});\n    }, handlerExecutionContext);\n  };\n  CreateDeliveryStreamCommand.prototype.serialize = function (input, context) {\n    return serializeAws_json1_1CreateDeliveryStreamCommand(input, context);\n  };\n  CreateDeliveryStreamCommand.prototype.deserialize = function (output, context) {\n    return deserializeAws_json1_1CreateDeliveryStreamCommand(output, context);\n  };\n  return CreateDeliveryStreamCommand;\n}($Command);\nexport { CreateDeliveryStreamCommand };","map":{"version":3,"names":["CreateDeliveryStreamInput","CreateDeliveryStreamOutput","deserializeAws_json1_1CreateDeliveryStreamCommand","serializeAws_json1_1CreateDeliveryStreamCommand","getSerdePlugin","Command","$Command","CreateDeliveryStreamCommand","_super","__extends","input","_this","call","prototype","resolveMiddleware","clientStack","configuration","options","middlewareStack","use","serialize","deserialize","stack","concat","logger","clientName","commandName","handlerExecutionContext","inputFilterSensitiveLog","filterSensitiveLog","outputFilterSensitiveLog","requestHandler","resolve","request","handle","context","output"],"sources":["/Users/yannellym/Desktop/iwantapet/node_modules/@aws-sdk/client-firehose/commands/CreateDeliveryStreamCommand.ts"],"sourcesContent":["import { FirehoseClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from \"../FirehoseClient\";\nimport { CreateDeliveryStreamInput, CreateDeliveryStreamOutput } from \"../models/models_0\";\nimport {\n  deserializeAws_json1_1CreateDeliveryStreamCommand,\n  serializeAws_json1_1CreateDeliveryStreamCommand,\n} from \"../protocols/Aws_json1_1\";\nimport { getSerdePlugin } from \"@aws-sdk/middleware-serde\";\nimport { HttpRequest as __HttpRequest, HttpResponse as __HttpResponse } from \"@aws-sdk/protocol-http\";\nimport { Command as $Command } from \"@aws-sdk/smithy-client\";\nimport {\n  FinalizeHandlerArguments,\n  Handler,\n  HandlerExecutionContext,\n  MiddlewareStack,\n  HttpHandlerOptions as __HttpHandlerOptions,\n  MetadataBearer as __MetadataBearer,\n  SerdeContext as __SerdeContext,\n} from \"@aws-sdk/types\";\n\nexport type CreateDeliveryStreamCommandInput = CreateDeliveryStreamInput;\nexport type CreateDeliveryStreamCommandOutput = CreateDeliveryStreamOutput & __MetadataBearer;\n\n/**\n * <p>Creates a Kinesis Data Firehose delivery stream.</p>\n *\n *          <p>By default, you can create up to 50 delivery streams per AWS Region.</p>\n *          <p>This is an asynchronous operation that immediately returns. The initial status of the\n *          delivery stream is <code>CREATING</code>. After the delivery stream is created, its status\n *          is <code>ACTIVE</code> and it now accepts data. If the delivery stream creation fails, the\n *          status transitions to <code>CREATING_FAILED</code>. Attempts to send data to a delivery\n *          stream that is not in the <code>ACTIVE</code> state cause an exception. To check the state\n *          of a delivery stream, use <a>DescribeDeliveryStream</a>.</p>\n *          <p>If the status of a delivery stream is <code>CREATING_FAILED</code>, this status\n *          doesn't change, and you can't invoke <code>CreateDeliveryStream</code> again on it.\n *          However, you can invoke the <a>DeleteDeliveryStream</a> operation to delete\n *          it.</p>\n *          <p>A Kinesis Data Firehose delivery stream can be configured to receive records directly\n *          from providers using <a>PutRecord</a> or <a>PutRecordBatch</a>, or it\n *          can be configured to use an existing Kinesis stream as its source. To specify a Kinesis\n *          data stream as input, set the <code>DeliveryStreamType</code> parameter to\n *             <code>KinesisStreamAsSource</code>, and provide the Kinesis stream Amazon Resource Name\n *          (ARN) and role ARN in the <code>KinesisStreamSourceConfiguration</code>\n *          parameter.</p>\n *          <p>To create a delivery stream with server-side encryption (SSE) enabled, include <a>DeliveryStreamEncryptionConfigurationInput</a> in your request. This is\n *          optional. You can also invoke <a>StartDeliveryStreamEncryption</a> to turn on\n *          SSE for an existing delivery stream that doesn't have SSE enabled.</p>\n *          <p>A delivery stream is configured with a single destination: Amazon S3, Amazon ES,\n *          Amazon Redshift, or Splunk. You must specify only one of the following destination\n *          configuration parameters: <code>ExtendedS3DestinationConfiguration</code>,\n *             <code>S3DestinationConfiguration</code>,\n *             <code>ElasticsearchDestinationConfiguration</code>,\n *             <code>RedshiftDestinationConfiguration</code>, or\n *             <code>SplunkDestinationConfiguration</code>.</p>\n *          <p>When you specify <code>S3DestinationConfiguration</code>, you can also provide the\n *          following optional values: BufferingHints, <code>EncryptionConfiguration</code>, and\n *             <code>CompressionFormat</code>. By default, if no <code>BufferingHints</code> value is\n *          provided, Kinesis Data Firehose buffers data up to 5 MB or for 5 minutes, whichever\n *          condition is satisfied first. <code>BufferingHints</code> is a hint, so there are some\n *          cases where the service cannot adhere to these conditions strictly. For example, record\n *          boundaries might be such that the size is a little over or under the configured buffering\n *          size. By default, no encryption is performed. We strongly recommend that you enable\n *          encryption to ensure secure data storage in Amazon S3.</p>\n *\n *          <p>A few notes about Amazon Redshift as a destination:</p>\n *          <ul>\n *             <li>\n *                <p>An Amazon Redshift destination requires an S3 bucket as intermediate location.\n *                Kinesis Data Firehose first delivers data to Amazon S3 and then uses\n *                   <code>COPY</code> syntax to load data into an Amazon Redshift table. This is\n *                specified in the <code>RedshiftDestinationConfiguration.S3Configuration</code>\n *                parameter.</p>\n *\n *             </li>\n *             <li>\n *                <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be\n *                specified in <code>RedshiftDestinationConfiguration.S3Configuration</code> because\n *                the Amazon Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't\n *                support these compression formats.</p>\n *             </li>\n *             <li>\n *                <p>We strongly recommend that you use the user name and password you provide\n *                exclusively with Kinesis Data Firehose, and that the permissions for the account are\n *                restricted for Amazon Redshift <code>INSERT</code> permissions.</p>\n *\n *             </li>\n *          </ul>\n *          <p>Kinesis Data Firehose assumes the IAM role that is configured as part of the\n *          destination. The role should allow the Kinesis Data Firehose principal to assume the role,\n *          and the role should have permissions that allow the service to deliver the data. For more\n *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n *             Firehose Access to an Amazon S3 Destination</a> in the <i>Amazon Kinesis Data\n *             Firehose Developer Guide</i>.</p>\n */\nexport class CreateDeliveryStreamCommand extends $Command<\n  CreateDeliveryStreamCommandInput,\n  CreateDeliveryStreamCommandOutput,\n  FirehoseClientResolvedConfig\n> {\n  // Start section: command_properties\n  // End section: command_properties\n\n  constructor(readonly input: CreateDeliveryStreamCommandInput) {\n    // Start section: command_constructor\n    super();\n    // End section: command_constructor\n  }\n\n  /**\n   * @internal\n   */\n  resolveMiddleware(\n    clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>,\n    configuration: FirehoseClientResolvedConfig,\n    options?: __HttpHandlerOptions\n  ): Handler<CreateDeliveryStreamCommandInput, CreateDeliveryStreamCommandOutput> {\n    this.middlewareStack.use(getSerdePlugin(configuration, this.serialize, this.deserialize));\n\n    const stack = clientStack.concat(this.middlewareStack);\n\n    const { logger } = configuration;\n    const clientName = \"FirehoseClient\";\n    const commandName = \"CreateDeliveryStreamCommand\";\n    const handlerExecutionContext: HandlerExecutionContext = {\n      logger,\n      clientName,\n      commandName,\n      inputFilterSensitiveLog: CreateDeliveryStreamInput.filterSensitiveLog,\n      outputFilterSensitiveLog: CreateDeliveryStreamOutput.filterSensitiveLog,\n    };\n    const { requestHandler } = configuration;\n    return stack.resolve(\n      (request: FinalizeHandlerArguments<any>) =>\n        requestHandler.handle(request.request as __HttpRequest, options || {}),\n      handlerExecutionContext\n    );\n  }\n\n  private serialize(input: CreateDeliveryStreamCommandInput, context: __SerdeContext): Promise<__HttpRequest> {\n    return serializeAws_json1_1CreateDeliveryStreamCommand(input, context);\n  }\n\n  private deserialize(output: __HttpResponse, context: __SerdeContext): Promise<CreateDeliveryStreamCommandOutput> {\n    return deserializeAws_json1_1CreateDeliveryStreamCommand(output, context);\n  }\n\n  // Start section: command_body_extra\n  // End section: command_body_extra\n}\n"],"mappings":";AACA,SAASA,yBAAyB,EAAEC,0BAA0B,QAAQ,oBAAoB;AAC1F,SACEC,iDAAiD,EACjDC,+CAA+C,QAC1C,0BAA0B;AACjC,SAASC,cAAc,QAAQ,2BAA2B;AAE1D,SAASC,OAAO,IAAIC,QAAQ,QAAQ,wBAAwB;AAc5D;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuEA,IAAAC,2BAAA,0BAAAC,MAAA;EAAiDC,SAAA,CAAAF,2BAAA,EAAAC,MAAA;EAK/C;EACA;EAEA,SAAAD,4BAAqBG,KAAuC;IAA5D,IAAAC,KAAA;IACE;IACAH,MAAA,CAAAI,IAAA,MAAO;IAFYD,KAAA,CAAAD,KAAK,GAALA,KAAK;;IAGxB;EACF;EAEA;;;EAGAH,2BAAA,CAAAM,SAAA,CAAAC,iBAAiB,GAAjB,UACEC,WAAmE,EACnEC,aAA2C,EAC3CC,OAA8B;IAE9B,IAAI,CAACC,eAAe,CAACC,GAAG,CAACf,cAAc,CAACY,aAAa,EAAE,IAAI,CAACI,SAAS,EAAE,IAAI,CAACC,WAAW,CAAC,CAAC;IAEzF,IAAMC,KAAK,GAAGP,WAAW,CAACQ,MAAM,CAAC,IAAI,CAACL,eAAe,CAAC;IAE9C,IAAAM,MAAM,GAAKR,aAAa,CAAAQ,MAAlB;IACd,IAAMC,UAAU,GAAG,gBAAgB;IACnC,IAAMC,WAAW,GAAG,6BAA6B;IACjD,IAAMC,uBAAuB,GAA4B;MACvDH,MAAM,EAAAA,MAAA;MACNC,UAAU,EAAAA,UAAA;MACVC,WAAW,EAAAA,WAAA;MACXE,uBAAuB,EAAE5B,yBAAyB,CAAC6B,kBAAkB;MACrEC,wBAAwB,EAAE7B,0BAA0B,CAAC4B;KACtD;IACO,IAAAE,cAAc,GAAKf,aAAa,CAAAe,cAAlB;IACtB,OAAOT,KAAK,CAACU,OAAO,CAClB,UAACC,OAAsC;MACrC,OAAAF,cAAc,CAACG,MAAM,CAACD,OAAO,CAACA,OAAwB,EAAEhB,OAAO,IAAI,EAAE,CAAC;IAAtE,CAAsE,EACxEU,uBAAuB,CACxB;EACH,CAAC;EAEOpB,2BAAA,CAAAM,SAAA,CAAAO,SAAS,GAAjB,UAAkBV,KAAuC,EAAEyB,OAAuB;IAChF,OAAOhC,+CAA+C,CAACO,KAAK,EAAEyB,OAAO,CAAC;EACxE,CAAC;EAEO5B,2BAAA,CAAAM,SAAA,CAAAQ,WAAW,GAAnB,UAAoBe,MAAsB,EAAED,OAAuB;IACjE,OAAOjC,iDAAiD,CAACkC,MAAM,EAAED,OAAO,CAAC;EAC3E,CAAC;EAIH,OAAA5B,2BAAC;AAAD,CAAC,CAtDgDD,QAAQ"},"metadata":{},"sourceType":"module","externalDependencies":[]}